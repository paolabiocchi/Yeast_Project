{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\dask\\dataframe\\__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import os.path\n",
    "from preprocessing import *\n",
    "from skorch import NeuralNetRegressor\n",
    "from torch import nn, optim\n",
    "from skorch.callbacks import EarlyStopping\n",
    "from skorch.callbacks import EpochScoring\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing the data...\n",
      "moving to y\n",
      "three\n",
      "Mean:\n",
      " YPD_doublingtime   -0.041351\n",
      "dtype: float64\n",
      "\n",
      "Variance:\n",
      " YPD_doublingtime    0.050213\n",
      "dtype: float64\n",
      "\n",
      "Median:\n",
      " YPD_doublingtime    0.002067\n",
      "dtype: float64\n",
      "\n",
      "Max:\n",
      " <bound method DataFrame.max of      YPD_doublingtime\n",
      "0           -0.280671\n",
      "1           -1.543014\n",
      "2            0.144228\n",
      "3           -0.088871\n",
      "4           -0.327364\n",
      "..                ...\n",
      "787          0.118617\n",
      "788          0.071000\n",
      "789         -0.054520\n",
      "790          0.025230\n",
      "791          0.011967\n",
      "\n",
      "[792 rows x 1 columns]>\n",
      "The DataFrame does not contain any NaN values.\n",
      "1\n",
      "The DataFrame does not contain any NaN values.\n",
      "2\n",
      "The DataFrame does not contain any NaN values.\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "X_file = \"data/X_matrix.csv\"\n",
    "Y_file = \"data/Y_matrix.csv\"\n",
    "\n",
    "print(\"Loading and preprocessing the data...\")\n",
    "\n",
    "# Load the column names (header)\n",
    "column_names = np.genfromtxt(X_file, delimiter=',', max_rows=1, dtype=str)[1:]  # Skip the first column if it's row names\n",
    "\n",
    "# Load the row names (index) from the first column and the data (excluding first column)\n",
    "data = np.loadtxt(X_file, delimiter=',', skiprows=1, usecols=range(1, 348523))\n",
    "row_names = np.loadtxt(X_file, delimiter=',', skiprows=1, usecols=0, dtype=str)\n",
    "\n",
    "# Create the DataFrame\n",
    "x2_df = pd.DataFrame(data, index=row_names, columns=column_names)\n",
    "x2_df = pd.DataFrame(data, columns=column_names)\n",
    "\n",
    "print(\"moving to y\")\n",
    "y2_df = pd.read_csv(Y_file)\n",
    "print(\"three\")\n",
    "\n",
    "\n",
    "x_data_f = x2_df.drop(x2_df.columns[0], axis=1)\n",
    "y_data_f = y2_df.drop(y2_df.columns[0], axis=1)\n",
    "\n",
    "x_data_f, y_data_f = preprocessed_data(x_data_f, y_data_f, y=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Préparation des données...\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1        \u001b[36m0.1352\u001b[0m        \u001b[32m0.0287\u001b[0m  40.2976\n",
      "      2        \u001b[36m0.0296\u001b[0m        \u001b[32m0.0145\u001b[0m  39.9460\n",
      "      3        \u001b[36m0.0152\u001b[0m        \u001b[32m0.0125\u001b[0m  40.0033\n",
      "      4        \u001b[36m0.0137\u001b[0m        \u001b[32m0.0114\u001b[0m  40.5287\n",
      "      5        \u001b[36m0.0079\u001b[0m        0.0115  40.6101\n",
      "      6        0.0094        0.0116  39.9414\n",
      "      7        0.0089        \u001b[32m0.0102\u001b[0m  39.9684\n",
      "      8        \u001b[36m0.0071\u001b[0m        \u001b[32m0.0094\u001b[0m  40.0087\n",
      "      9        \u001b[36m0.0057\u001b[0m        0.0105  40.0464\n",
      "     10        \u001b[36m0.0046\u001b[0m        0.0096  40.0399\n",
      "     11        \u001b[36m0.0043\u001b[0m        0.0103  39.8641\n",
      "     12        0.0043        0.0100  40.0466\n",
      "     13        0.0049        \u001b[32m0.0091\u001b[0m  40.0029\n",
      "     14        0.0053        0.0110  39.9769\n",
      "     15        0.0068        0.0107  40.1181\n",
      "     16        0.0043        0.0112  39.8304\n",
      "     17        \u001b[36m0.0033\u001b[0m        \u001b[32m0.0085\u001b[0m  40.0311\n",
      "     18        \u001b[36m0.0032\u001b[0m        0.0104  39.9724\n",
      "     19        0.0032        0.0091  40.0820\n",
      "     20        \u001b[36m0.0031\u001b[0m        0.0086  39.9648\n",
      "     21        0.0042        0.0088  39.9797\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Best Parameters: {'lr': 0.0001, 'max_epochs': 150, 'module__dropout_rate': 0.01, 'optimizer': <class 'torch.optim.adam.Adam'>}\n",
      "  epoch    train_loss    valid_loss      dur\n",
      "-------  ------------  ------------  -------\n",
      "      1       \u001b[36m-0.3492\u001b[0m       \u001b[32m-0.0281\u001b[0m  11.9161\n",
      "      2       \u001b[36m-0.0469\u001b[0m       -0.0471  11.8669\n",
      "      3       \u001b[36m-0.0362\u001b[0m       -0.0318  11.5161\n",
      "      4       \u001b[36m-0.0240\u001b[0m       \u001b[32m-0.0269\u001b[0m  11.7101\n",
      "      5       \u001b[36m-0.0215\u001b[0m       \u001b[32m-0.0226\u001b[0m  11.6333\n",
      "      6       \u001b[36m-0.0203\u001b[0m       \u001b[32m-0.0181\u001b[0m  11.4883\n",
      "      7       \u001b[36m-0.0122\u001b[0m       \u001b[32m-0.0106\u001b[0m  11.7225\n",
      "      8       \u001b[36m-0.0086\u001b[0m       -0.0114  11.5575\n",
      "      9       \u001b[36m-0.0053\u001b[0m       -0.0107  11.4000\n",
      "     10       -0.0060       \u001b[32m-0.0088\u001b[0m  11.4852\n",
      "     11       \u001b[36m-0.0044\u001b[0m       -0.0096  11.4618\n",
      "     12       \u001b[36m-0.0040\u001b[0m       -0.0091  11.6093\n",
      "     13       \u001b[36m-0.0032\u001b[0m       -0.0088  11.6679\n",
      "     14       \u001b[36m-0.0027\u001b[0m       \u001b[32m-0.0085\u001b[0m  11.8266\n",
      "     15       -0.0028       \u001b[32m-0.0085\u001b[0m  11.6298\n",
      "     16       \u001b[36m-0.0024\u001b[0m       \u001b[32m-0.0078\u001b[0m  12.2894\n",
      "     17       -0.0026       -0.0089  12.2563\n",
      "     18       -0.0027       -0.0090  11.7803\n",
      "     19       \u001b[36m-0.0024\u001b[0m       -0.0086  11.6610\n",
      "     20       \u001b[36m-0.0023\u001b[0m       -0.0081  11.5267\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Mean Squared Error: 0.00263678515329957\n",
      "R2 score: 0.3441627025604248\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#V2\n",
    "\n",
    "# Préparation des données\n",
    "print(\"Préparation des données...\")\n",
    "\n",
    "# Number of input features\n",
    "n_input_features = x_data_f.shape[1]\n",
    "\n",
    "# Define an enhanced neural network\n",
    "class EnhancedRegressionNet(nn.Module):\n",
    "    def __init__(self, n_input_features, dropout_rate, n_neurons_1=1024, n_neurons_2=512):\n",
    "        super(EnhancedRegressionNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_input_features, n_neurons_1)  # n_input_features\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(n_neurons_1, n_neurons_2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.fc3 = nn.Linear(n_neurons_2, 1)  # Output layer remains 2D\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x  # Do not squeeze the output; output remains shape [batch_size, 1]\n",
    "\n",
    "# Ensure both x_data_f and y_data_f are converted to float32\n",
    "x_data_f = x_data_f.astype(np.float32)  # Cast features to float32\n",
    "y_data_f = y_data_f.astype(np.float32)  # Cast target to float32\n",
    "\n",
    "# Define scoring callbacks for training and validation loss\n",
    "train_loss = EpochScoring(scoring='neg_mean_squared_error', on_train=True, name='train_loss', lower_is_better=False)\n",
    "valid_loss = EpochScoring(scoring='neg_mean_squared_error', name='valid_loss', lower_is_better=False)\n",
    "\n",
    "# Neural Network Regressor\n",
    "net = NeuralNetRegressor(\n",
    "    module=EnhancedRegressionNet,\n",
    "    module__n_input_features=n_input_features,  # n_input_features\n",
    "    criterion=nn.MSELoss,\n",
    "    optimizer=optim.Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    iterator_train__batch_size=32,\n",
    "    callbacks=[EarlyStopping(patience=5)],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'module__dropout_rate': [0.01],\n",
    "    'lr': [0.0001],\n",
    "    'max_epochs': [150],\n",
    "    'optimizer': [optim.Adam],\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(net, param_grid=param_grid, cv=KFold(n_splits=6), scoring='neg_mean_squared_error', n_jobs=2)\n",
    "\n",
    "# Ensure y_data_f has the correct shape (2D) for PyTorch\n",
    "y_data_f_reshaped = y_data_f.reshape(-1, 1)\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(x_data_f.values, y_data_f_reshaped)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Training of the model\n",
    "best_net = NeuralNetRegressor(\n",
    "    module=EnhancedRegressionNet,\n",
    "    module__n_input_features=n_input_features,\n",
    "    module__n_neurons_1=1024,                   # Neurons in the first hidden layer\n",
    "    module__n_neurons_2=512,\n",
    "    module__dropout_rate=best_params['module__dropout_rate'],\n",
    "    criterion=nn.MSELoss,\n",
    "    max_epochs=best_params['max_epochs'],\n",
    "    optimizer=best_params['optimizer'],\n",
    "    lr=best_params['lr'],\n",
    "    iterator_train__shuffle=True,\n",
    "    callbacks=[EarlyStopping(patience=5), train_loss, valid_loss],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the final model\n",
    "best_net.fit(x_data_f.values, y_data_f_reshaped)\n",
    "\n",
    "# Predictions\n",
    "Y_pred = best_net.predict(x_data_f.values)\n",
    "\n",
    "# Reshape predictions for consistency (if needed)\n",
    "Y_pred = Y_pred.reshape(-1, 1)\n",
    "\n",
    "# Rescale predictions if necessary (using y_reverse, if required)\n",
    "Y_pred_rev = y_reverse(Y_pred)  # Uncomment if using y_reverse function\n",
    "\n",
    "# Create a DataFrame with predictions\n",
    "id_array = np.arange(1, len(Y_pred) + 1)\n",
    "final_df = pd.DataFrame({\n",
    "    'ID': id_array,\n",
    "    'division_rate': Y_pred_rev.flatten()\n",
    "})\n",
    "\n",
    "# Save the new DataFrame to a CSV file\n",
    "final_csv = final_df.to_csv(\"Data\\\\results_nn3.csv\", index=False)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_data_f_reshaped, Y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "r2 = r2_score(y_data_f_reshaped, Y_pred)\n",
    "print(f'R2 score: {r2}')\n",
    "\n",
    "# Extract training and validation loss for a plot\n",
    "train_losses = best_net.history[:, 'train_loss']\n",
    "valid_losses = best_net.history[:, 'valid_loss']\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(valid_losses, label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Negative Mean Squared Error')\n",
    "plt.title('Training and Validation Loss per Epoch')\n",
    "plt.legend()\n",
    "plt.savefig(\"Data\\\\NNplot_nn3.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as model.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"saved_models/model_NN.pkl\", \"wb\") as file:\n",
    "    pickle.dump(best_net, file)\n",
    "print(\"Model saved as model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "with open(\"saved_models/model_NN.pkl\", \"rb\") as file:\n",
    "    loaded_model = pickle.load(file)\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:44<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m explainer \u001b[38;5;241m=\u001b[39m shap\u001b[38;5;241m.\u001b[39mKernelExplainer(best_net\u001b[38;5;241m.\u001b[39mpredict, shap\u001b[38;5;241m.\u001b[39msample(x_data_f, \u001b[38;5;241m20\u001b[39m))  \u001b[38;5;66;03m# Sample 100 rows for the baseline\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Compute SHAP values for a subset of data\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_data_f\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calculate for the first 200 rows\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Visualize SHAP values\u001b[39;00m\n\u001b[0;32m     13\u001b[0m shap\u001b[38;5;241m.\u001b[39msummary_plot(shap_values, x_data_f[:\u001b[38;5;241m20\u001b[39m], feature_names\u001b[38;5;241m=\u001b[39mx_data_f\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\shap\\explainers\\_kernel.py:271\u001b[0m, in \u001b[0;36mKernelExplainer.shap_values\u001b[1;34m(self, X, **kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_index:\n\u001b[0;32m    270\u001b[0m     data \u001b[38;5;241m=\u001b[39m convert_to_instance_with_index(data, column_name, index_value[i:i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m], index_name)\n\u001b[1;32m--> 271\u001b[0m explanations\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplain(data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgc_collect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    273\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\shap\\explainers\\_kernel.py:303\u001b[0m, in \u001b[0;36mKernelExplainer.explain\u001b[1;34m(self, incoming_instance, **kwargs)\u001b[0m\n\u001b[0;32m    299\u001b[0m match_instance_to_data(instance, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)\n\u001b[0;32m    301\u001b[0m \u001b[38;5;66;03m# find the feature groups we will test. If a feature does not change from its\u001b[39;00m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;66;03m# current value then we know it doesn't impact the model\u001b[39;00m\n\u001b[1;32m--> 303\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvaryingInds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvarying_groups\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mgroups \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvaryingFeatureGroups \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvaryingInds])\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\shap\\explainers\\_kernel.py:511\u001b[0m, in \u001b[0;36mKernelExplainer.varying_groups\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    509\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    510\u001b[0m         x_group \u001b[38;5;241m=\u001b[39m x_group\u001b[38;5;241m.\u001b[39mtodense()\n\u001b[1;32m--> 511\u001b[0m     num_mismatches \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrompyfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_equal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_group\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minds\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    512\u001b[0m     varying[i] \u001b[38;5;241m=\u001b[39m num_mismatches \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    513\u001b[0m varying_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnonzero(varying)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\shap\\explainers\\_kernel.py:496\u001b[0m, in \u001b[0;36mKernelExplainer.not_equal\u001b[1;34m(i, j)\u001b[0m\n\u001b[0;32m    494\u001b[0m number_types \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(i, number_types) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(j, number_types):\n\u001b[1;32m--> 496\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m j \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\numpy\\core\\numeric.py:2351\u001b[0m, in \u001b[0;36misclose\u001b[1;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[0;32m   2349\u001b[0m yfin \u001b[38;5;241m=\u001b[39m isfinite(y)\n\u001b[0;32m   2350\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(xfin) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(yfin):\n\u001b[1;32m-> 2351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwithin_tol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2352\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2353\u001b[0m     finite \u001b[38;5;241m=\u001b[39m xfin \u001b[38;5;241m&\u001b[39m yfin\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\numpy\\core\\numeric.py:2331\u001b[0m, in \u001b[0;36misclose.<locals>.within_tol\u001b[1;34m(x, y, atol, rtol)\u001b[0m\n\u001b[0;32m   2330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwithin_tol\u001b[39m(x, y, atol, rtol):\n\u001b[1;32m-> 2331\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m errstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m), _no_nep50_warning():\n\u001b[0;32m   2332\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m less_equal(\u001b[38;5;28mabs\u001b[39m(x\u001b[38;5;241m-\u001b[39my), atol \u001b[38;5;241m+\u001b[39m rtol \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mabs\u001b[39m(y))\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\numpy\\core\\_ufunc_config.py:436\u001b[0m, in \u001b[0;36merrstate.__exit__\u001b[1;34m(self, *exc_info)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mexc_info):\n\u001b[1;32m--> 436\u001b[0m     seterr(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moldstate)\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _Unspecified:\n\u001b[0;32m    438\u001b[0m         seterrcall(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moldcall)\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\numpy\\core\\_ufunc_config.py:113\u001b[0m, in \u001b[0;36mseterr\u001b[1;34m(all, divide, over, under, invalid)\u001b[0m\n\u001b[0;32m    110\u001b[0m pyvals \u001b[38;5;241m=\u001b[39m umath\u001b[38;5;241m.\u001b[39mgeterrobj()\n\u001b[0;32m    111\u001b[0m old \u001b[38;5;241m=\u001b[39m geterr()\n\u001b[1;32m--> 113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdivide\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m:\n\u001b[0;32m    114\u001b[0m     divide \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mall\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m old[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdivide\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m over \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# SHAP Explainer: Use KernelExplainer for skorch models\n",
    "explainer = shap.KernelExplainer(best_net.predict, shap.sample(x_data_f, 20))  # Sample 100 rows for the baseline\n",
    "\n",
    "# Compute SHAP values for a subset of data\n",
    "shap_values = explainer.shap_values(x_data_f[:20])  # Calculate for the first 200 rows\n",
    "\n",
    "# Visualize SHAP values\n",
    "shap.summary_plot(shap_values, x_data_f[:20], feature_names=x_data_f.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Create SHAP explainer\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m explainer \u001b[38;5;241m=\u001b[39m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDeepExplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_data_f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Initialize an array to store SHAP values\u001b[39;00m\n\u001b[0;32m     13\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\shap\\explainers\\_deep\\__init__.py:90\u001b[0m, in \u001b[0;36mDeepExplainer.__init__\u001b[1;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(model, masker)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m framework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorflow\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m---> 90\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer \u001b[38;5;241m=\u001b[39m \u001b[43mTFDeep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_phase_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m framework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexplainer \u001b[38;5;241m=\u001b[39m PyTorchDeep(model, data)\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\shap\\explainers\\_deep\\deep_tf.py:84\u001b[0m, in \u001b[0;36mTFDeep.__init__\u001b[1;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tf, tf_ops, tf_backprop, tf_execute, tf_gradients_impl\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backprop \u001b[38;5;28;01mas\u001b[39;00m tf_backprop\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m execute \u001b[38;5;28;01mas\u001b[39;00m tf_execute\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     87\u001b[0m         ops \u001b[38;5;28;01mas\u001b[39;00m tf_ops,\n\u001b[0;32m     88\u001b[0m     )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#imporatnces with SHAP\n",
    "\n",
    "import shap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create SHAP explainer\n",
    "explainer = shap.DeepExplainer(best_net, x_data_f.values.astype(np.float32))\n",
    "\n",
    "# Initialize an array to store SHAP values\n",
    "shap_values = []\n",
    "\n",
    "# Progress bar\n",
    "with tqdm(total=len(x_data_f), desc=\"Computing SHAP Values\") as pbar:\n",
    "    for i in range(len(x_data_f)):\n",
    "        shap_value = explainer.shap_values(x_data_f.values[i:i+1].astype(np.float32))  # Compute SHAP for one sample\n",
    "        shap_values.append(shap_value[0])  # SHAP for the first output class\n",
    "        pbar.update(1)\n",
    "print(\"1\")\n",
    "\n",
    "# Convert SHAP values to a numpy array\n",
    "shap_values = np.vstack(shap_values)\n",
    "\n",
    "# Summarize feature importance\n",
    "feature_importances = pd.DataFrame({\n",
    "    \"Feature\": x_data_f.columns,\n",
    "    \"Importance\": np.abs(shap_values).mean(axis=0)  # Mean absolute SHAP values\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Select the top 10 features\n",
    "top_10_features = feature_importances.head(10)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 9))\n",
    "plt.barh(top_10_features[\"Feature\"], top_10_features[\"Importance\"], align=\"center\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Mean Absolute SHAP Values\")\n",
    "plt.title(\"Top 10 Most Important Features (SHAP)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Data\\\\SHAP_Feature_Importance_Plot.png\")\n",
    "plt.show()\n",
    "\n",
    "# Display top 10 features\n",
    "print(top_10_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Integrated Gradients:   0%|          | 0/792 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "<class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n  module_=EnhancedRegressionNet(\n    (fc1): Linear(in_features=334898, out_features=128, bias=True)\n    (relu1): ReLU()\n    (dropout1): Dropout(p=0.012, inplace=False)\n    (fc2): Linear(in_features=128, out_features=128, bias=True)\n    (relu2): ReLU()\n    (dropout2): Dropout(p=0.012, inplace=False)\n    (fc3): Linear(in_features=128, out_features=1, bias=True)\n  ),\n) is not a callable object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(x_tensor), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing Integrated Gradients\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(x_tensor)):\n\u001b[1;32m---> 21\u001b[0m         attr, _ \u001b[38;5;241m=\u001b[39m \u001b[43mig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_convergence_delta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Compute IG for one sample\u001b[39;00m\n\u001b[0;32m     22\u001b[0m         attributions\u001b[38;5;241m.\u001b[39mappend(attr\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     23\u001b[0m         pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\captum\\log\\__init__.py:42\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\captum\\attr\\_core\\integrated_gradients.py:286\u001b[0m, in \u001b[0;36mIntegratedGradients.attribute\u001b[1;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001b[0m\n\u001b[0;32m    274\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m _batch_attribution(\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    276\u001b[0m         num_examples,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    283\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    284\u001b[0m     )\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 286\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attribute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbaselines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaselines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_convergence_delta:\n\u001b[0;32m    296\u001b[0m     start_point, end_point \u001b[38;5;241m=\u001b[39m baselines, inputs\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\captum\\attr\\_core\\integrated_gradients.py:351\u001b[0m, in \u001b[0;36mIntegratedGradients._attribute\u001b[1;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, step_sizes_and_alphas)\u001b[0m\n\u001b[0;32m    348\u001b[0m expanded_target \u001b[38;5;241m=\u001b[39m _expand_target(target, n_steps)\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# grads: dim -> (bsz * #steps x inputs[0].shape[1:], ...)\u001b[39;00m\n\u001b[1;32m--> 351\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaled_features_tpl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_ind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpanded_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_additional_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;66;03m# flattening grads so that we can multilpy it with step-size\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;66;03m# calling contiguous to avoid `memory whole` problems\u001b[39;00m\n\u001b[0;32m    360\u001b[0m scaled_grads \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    361\u001b[0m     grad\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(n_steps, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(step_sizes)\u001b[38;5;241m.\u001b[39mview(n_steps, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(grad\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m grad \u001b[38;5;129;01min\u001b[39;00m grads\n\u001b[0;32m    364\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\captum\\_utils\\gradient.py:112\u001b[0m, in \u001b[0;36mcompute_gradients\u001b[1;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03mComputes gradients of the output with respect to inputs for an\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03marbitrary forward function.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m                arguments) if no additional arguments are required\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;66;03m# runs forward pass\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_run_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_ind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, (\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget not provided when necessary, cannot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m take gradient with respect to multiple outputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    116\u001b[0m     )\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# torch.unbind(forward_out) is a list of scalar tensor tuples and\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# contains batch_size * #steps elements\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\captum\\_utils\\common.py:521\u001b[0m, in \u001b[0;36m_run_forward\u001b[1;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_forward\u001b[39m(\n\u001b[0;32m    516\u001b[0m     forward_func: Callable,\n\u001b[0;32m    517\u001b[0m     inputs: Any,\n\u001b[0;32m    518\u001b[0m     target: TargetType \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    519\u001b[0m     additional_forward_args: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    520\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 521\u001b[0m     forward_func_args \u001b[38;5;241m=\u001b[39m \u001b[43msignature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforward_func\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mparameters\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(forward_func_args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    523\u001b[0m         output \u001b[38;5;241m=\u001b[39m forward_func()\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\inspect.py:3254\u001b[0m, in \u001b[0;36msignature\u001b[1;34m(obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[0;32m   3252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msignature\u001b[39m(obj, \u001b[38;5;241m*\u001b[39m, follow_wrapped\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   3253\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 3254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_wrapped\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3255\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\inspect.py:3002\u001b[0m, in \u001b[0;36mSignature.from_callable\u001b[1;34m(cls, obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[0;32m   2998\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   2999\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_callable\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   3000\u001b[0m                   follow_wrapped\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   3001\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 3002\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_signature_from_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigcls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3003\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mfollow_wrapper_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3004\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\inspect.py:2396\u001b[0m, in \u001b[0;36m_signature_from_callable\u001b[1;34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[0m\n\u001b[0;32m   2387\u001b[0m _get_signature_of \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(_signature_from_callable,\n\u001b[0;32m   2388\u001b[0m                             follow_wrapper_chains\u001b[38;5;241m=\u001b[39mfollow_wrapper_chains,\n\u001b[0;32m   2389\u001b[0m                             skip_bound_arg\u001b[38;5;241m=\u001b[39mskip_bound_arg,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2392\u001b[0m                             sigcls\u001b[38;5;241m=\u001b[39msigcls,\n\u001b[0;32m   2393\u001b[0m                             eval_str\u001b[38;5;241m=\u001b[39meval_str)\n\u001b[0;32m   2395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(obj):\n\u001b[1;32m-> 2396\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m is not a callable object\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj))\n\u001b[0;32m   2398\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, types\u001b[38;5;241m.\u001b[39mMethodType):\n\u001b[0;32m   2399\u001b[0m     \u001b[38;5;66;03m# In this case we skip the first parameter of the underlying\u001b[39;00m\n\u001b[0;32m   2400\u001b[0m     \u001b[38;5;66;03m# function (usually `self` or `cls`).\u001b[39;00m\n\u001b[0;32m   2401\u001b[0m     sig \u001b[38;5;241m=\u001b[39m _get_signature_of(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: <class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n  module_=EnhancedRegressionNet(\n    (fc1): Linear(in_features=334898, out_features=128, bias=True)\n    (relu1): ReLU()\n    (dropout1): Dropout(p=0.012, inplace=False)\n    (fc2): Linear(in_features=128, out_features=128, bias=True)\n    (relu2): ReLU()\n    (dropout2): Dropout(p=0.012, inplace=False)\n    (fc3): Linear(in_features=128, out_features=1, bias=True)\n  ),\n) is not a callable object"
     ]
    }
   ],
   "source": [
    "#importances with captum\n",
    "\n",
    "import torch\n",
    "from captum.attr import IntegratedGradients\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "x_tensor = torch.tensor(x_data_f.values.astype(np.float32))\n",
    "y_tensor = torch.tensor(y_data_f.astype(np.float32))\n",
    "\n",
    "# Initialize Integrated Gradients\n",
    "ig = IntegratedGradients(best_net)\n",
    "\n",
    "# Initialize an array to store attributions\n",
    "attributions = []\n",
    "\n",
    "# Progress bar\n",
    "with tqdm(total=len(x_tensor), desc=\"Computing Integrated Gradients\") as pbar:\n",
    "    for i in range(len(x_tensor)):\n",
    "        attr, _ = ig.attribute(x_tensor[i:i+1], target=0, return_convergence_delta=True)  # Compute IG for one sample\n",
    "        attributions.append(attr.detach().numpy())\n",
    "        pbar.update(1)\n",
    "\n",
    "# Aggregate absolute values of attributions across samples for each feature\n",
    "attributions = np.vstack(attributions)\n",
    "feature_importances = np.abs(attributions).mean(axis=0)\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    \"Feature\": x_data_f.columns,\n",
    "    \"Importance\": feature_importances\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Select the top 10 features\n",
    "top_10_features = feature_importance_df.head(10)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 9))\n",
    "plt.barh(top_10_features[\"Feature\"], top_10_features[\"Importance\"], align=\"center\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Integrated Gradients Importance\")\n",
    "plt.title(\"Top 10 Most Important Features (Captum)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Data\\\\Captum_Feature_Importance_Plot.png\")\n",
    "plt.show()\n",
    "\n",
    "# Display top 10 features\n",
    "print(top_10_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "BrokenProcessPool",
     "evalue": "A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 426, in _process_worker\n    call_item = call_queue.get(block=True, timeout=timeout)\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\multiprocessing\\queues.py\", line 122, in get\n    return _ForkingPickler.loads(res)\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\skorch\\net.py\", line 2231, in __setstate__\n    cuda_attrs = torch.load(f, **load_kwargs)\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\serialization.py\", line 1025, in load\n    return _load(opened_zipfile,\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\serialization.py\", line 1446, in _load\n    result = unpickler.load()\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\serialization.py\", line 1439, in find_class\n    return super().find_class(mod_name, name)\nAttributeError: Can't get attribute 'EnhancedRegressionNet' on <module '__main__' (built-in)>\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minspection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m permutation_importance\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Calculate permutation importance\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mpermutation_importance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbest_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Trained model\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_data_f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Input data\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_data_f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Target values\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mneg_mean_squared_error\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Scoring metric\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Number of permutations\u001b[39;49;00m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# For reproducibility\u001b[39;49;00m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     20\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Create a DataFrame for feature importance\u001b[39;00m\n\u001b[0;32m     23\u001b[0m feature_importances \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m\"\u001b[39m: x_data_f\u001b[38;5;241m.\u001b[39mcolumns,\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m\"\u001b[39m: results\u001b[38;5;241m.\u001b[39mimportances_mean\n\u001b[0;32m     26\u001b[0m })\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\inspection\\_permutation_importance.py:289\u001b[0m, in \u001b[0;36mpermutation_importance\u001b[1;34m(estimator, X, y, scoring, n_repeats, n_jobs, random_state, sample_weight, max_samples)\u001b[0m\n\u001b[0;32m    285\u001b[0m     scorer \u001b[38;5;241m=\u001b[39m _MultimetricScorer(scorers\u001b[38;5;241m=\u001b[39mscorers_dict)\n\u001b[0;32m    287\u001b[0m baseline_score \u001b[38;5;241m=\u001b[39m _weights_scorer(scorer, estimator, X, y, sample_weight)\n\u001b[1;32m--> 289\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_calculate_permutation_scores\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(baseline_score, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    306\u001b[0m         name: _create_importances_bunch(\n\u001b[0;32m    307\u001b[0m             baseline_score[name],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m baseline_score\n\u001b[0;32m    312\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\joblib\\parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1692\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1693\u001b[0m \n\u001b[0;32m   1694\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1697\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1699\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1700\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1702\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\joblib\\parallel.py:1734\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1730\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1734\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\joblib\\parallel.py:736\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    730\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\joblib\\parallel.py:754\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 754\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable."
     ]
    }
   ],
   "source": [
    "'''\n",
    "In a neural network, you don't directly get \"feature importances\" like in tree-based models (e.g., Random Forest or XGBoost). \n",
    "However, you can estimate feature importance by analyzing how sensitive the model's predictions are to changes in each feature. \n",
    "This method is often referred to as \"permutation importance\" or \"feature sensitivity analysis.\"\n",
    "\n",
    "Here's a Python script to compute and visualize the top 10 most important features based on permutation importance:\n",
    "'''\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Calculate permutation importance\n",
    "results = permutation_importance(\n",
    "    best_net,  # Trained model\n",
    "    x_data_f.values.astype(np.float32),  # Input data\n",
    "    y_data_f.astype(np.float32),  # Target values\n",
    "    scoring=\"neg_mean_squared_error\",  # Scoring metric\n",
    "    n_repeats=15,  # Number of permutations\n",
    "    random_state=42,  # For reproducibility\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Create a DataFrame for feature importance\n",
    "feature_importances = pd.DataFrame({\n",
    "    \"Feature\": x_data_f.columns,\n",
    "    \"Importance\": results.importances_mean\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Select the top 10 features\n",
    "top_10_features = feature_importances.head(10)\n",
    "\n",
    "# Plot the top 10 features\n",
    "plt.figure(figsize=(15, 9))\n",
    "plt.barh(top_10_features[\"Feature\"], top_10_features[\"Importance\"], align=\"center\")\n",
    "plt.gca().invert_yaxis()  # Highest importance on top\n",
    "plt.xlabel(\"Mean Importance\")\n",
    "plt.title(\"Top 10 Most Important Features\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Data\\\\Feature_Importance_Plot.png\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLCourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
