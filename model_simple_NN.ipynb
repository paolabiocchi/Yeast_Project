{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\dask\\dataframe\\__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import os.path\n",
    "from preprocessing import *\n",
    "from skorch import NeuralNetRegressor\n",
    "from torch import nn, optim\n",
    "from skorch.callbacks import EarlyStopping\n",
    "from skorch.callbacks import EpochScoring\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the data...\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "np.random.seed(10)\n",
    "\n",
    "X_file = \"data/X_matrix.csv\"\n",
    "Y_file = \"data/Y_matrix.csv\"\n",
    "\n",
    "print(\"Loading the data...\")\n",
    "x_df = pd.read_csv(X_file)\n",
    "y_df = pd.read_csv(Y_file)\n",
    "x_data_f, y_data_f = preprocessed_data(x_df, y_df)\n",
    "\n",
    "#x, y, x_test_try = preprocessed_data(path_train, path_cddd, path_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing the data...\n",
      "moving to y\n",
      "three\n",
      "The DataFrame does not contain any NaN values.\n",
      "1\n",
      "The DataFrame does not contain any NaN values.\n",
      "2\n",
      "The DataFrame does not contain any NaN values.\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "X_file = \"data/X_matrix.csv\"\n",
    "Y_file = \"data/Y_matrix.csv\"\n",
    "\n",
    "print(\"Loading and preprocessing the data...\")\n",
    "\n",
    "# Load the column names (header)\n",
    "column_names = np.genfromtxt(X_file, delimiter=',', max_rows=1, dtype=str)[1:]  # Skip the first column if it's row names\n",
    "\n",
    "# Load the row names (index) from the first column and the data (excluding first column)\n",
    "data = np.loadtxt(X_file, delimiter=',', skiprows=1, usecols=range(1, 348523))\n",
    "row_names = np.loadtxt(X_file, delimiter=',', skiprows=1, usecols=0, dtype=str)\n",
    "\n",
    "# Create the DataFrame\n",
    "x2_df = pd.DataFrame(data, index=row_names, columns=column_names)\n",
    "x2_df = pd.DataFrame(data, columns=column_names)\n",
    "\n",
    "print(\"moving to y\")\n",
    "y2_df = pd.read_csv(Y_file)\n",
    "print(\"three\")\n",
    "\n",
    "x_data_f = x2_df.drop(x2_df.columns[0], axis=1)\n",
    "y_data_f = y2_df.drop(y2_df.columns[0], axis=1)\n",
    "\n",
    "x_data_f, y_data_f = preprocessed_data(x_data_f, y_data_f, y=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(792, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_data_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(792, 1)\n",
      "(792,)\n"
     ]
    }
   ],
   "source": [
    "print(y_data_f.shape)\n",
    "y_data_f.head\n",
    "print(Y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Préparation des données...\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m0.4020\u001b[0m        \u001b[32m0.3273\u001b[0m  6.1132\n",
      "      2        \u001b[36m0.2663\u001b[0m        \u001b[32m0.2131\u001b[0m  5.7015\n",
      "      3        \u001b[36m0.1668\u001b[0m        \u001b[32m0.1381\u001b[0m  5.6776\n",
      "      4        \u001b[36m0.1112\u001b[0m        \u001b[32m0.0985\u001b[0m  5.6518\n",
      "      5        \u001b[36m0.0828\u001b[0m        \u001b[32m0.0755\u001b[0m  5.6796\n",
      "      6        \u001b[36m0.0645\u001b[0m        \u001b[32m0.0594\u001b[0m  5.6352\n",
      "      7        \u001b[36m0.0506\u001b[0m        \u001b[32m0.0470\u001b[0m  5.5940\n",
      "      8        \u001b[36m0.0387\u001b[0m        \u001b[32m0.0370\u001b[0m  5.6203\n",
      "      9        \u001b[36m0.0298\u001b[0m        \u001b[32m0.0294\u001b[0m  5.5917\n",
      "     10        \u001b[36m0.0231\u001b[0m        \u001b[32m0.0236\u001b[0m  5.6379\n",
      "     11        \u001b[36m0.0181\u001b[0m        \u001b[32m0.0195\u001b[0m  5.6089\n",
      "     12        \u001b[36m0.0142\u001b[0m        \u001b[32m0.0163\u001b[0m  5.5801\n",
      "     13        \u001b[36m0.0113\u001b[0m        \u001b[32m0.0141\u001b[0m  5.6194\n",
      "     14        \u001b[36m0.0094\u001b[0m        \u001b[32m0.0125\u001b[0m  5.6565\n",
      "     15        \u001b[36m0.0078\u001b[0m        \u001b[32m0.0114\u001b[0m  5.6767\n",
      "     16        \u001b[36m0.0067\u001b[0m        \u001b[32m0.0105\u001b[0m  5.6873\n",
      "     17        \u001b[36m0.0059\u001b[0m        \u001b[32m0.0099\u001b[0m  5.7247\n",
      "     18        \u001b[36m0.0052\u001b[0m        \u001b[32m0.0094\u001b[0m  5.6357\n",
      "     19        \u001b[36m0.0047\u001b[0m        \u001b[32m0.0091\u001b[0m  5.7325\n",
      "     20        \u001b[36m0.0043\u001b[0m        \u001b[32m0.0089\u001b[0m  5.6773\n",
      "     21        \u001b[36m0.0038\u001b[0m        \u001b[32m0.0088\u001b[0m  5.7509\n",
      "     22        \u001b[36m0.0037\u001b[0m        \u001b[32m0.0086\u001b[0m  5.8982\n",
      "     23        \u001b[36m0.0033\u001b[0m        \u001b[32m0.0085\u001b[0m  5.4505\n",
      "     24        0.0033        \u001b[32m0.0084\u001b[0m  5.5541\n",
      "     25        \u001b[36m0.0032\u001b[0m        \u001b[32m0.0084\u001b[0m  5.5643\n",
      "     26        \u001b[36m0.0030\u001b[0m        \u001b[32m0.0084\u001b[0m  5.5137\n",
      "     27        \u001b[36m0.0029\u001b[0m        \u001b[32m0.0083\u001b[0m  5.5725\n",
      "     28        0.0030        \u001b[32m0.0082\u001b[0m  5.4912\n",
      "     29        \u001b[36m0.0028\u001b[0m        \u001b[32m0.0082\u001b[0m  5.5119\n",
      "     30        \u001b[36m0.0026\u001b[0m        \u001b[32m0.0082\u001b[0m  5.5143\n",
      "     31        \u001b[36m0.0025\u001b[0m        \u001b[32m0.0082\u001b[0m  6.1839\n",
      "     32        0.0027        \u001b[32m0.0081\u001b[0m  7.5953\n",
      "     33        0.0025        \u001b[32m0.0081\u001b[0m  8.0942\n",
      "     34        \u001b[36m0.0022\u001b[0m        \u001b[32m0.0081\u001b[0m  8.2988\n",
      "     35        0.0024        \u001b[32m0.0080\u001b[0m  8.4092\n",
      "     36        \u001b[36m0.0022\u001b[0m        \u001b[32m0.0080\u001b[0m  8.4196\n",
      "     37        0.0023        \u001b[32m0.0080\u001b[0m  8.6309\n",
      "     38        0.0023        \u001b[32m0.0079\u001b[0m  8.7599\n",
      "     39        \u001b[36m0.0020\u001b[0m        \u001b[32m0.0079\u001b[0m  8.7850\n",
      "     40        0.0021        \u001b[32m0.0079\u001b[0m  8.6614\n",
      "     41        \u001b[36m0.0020\u001b[0m        \u001b[32m0.0078\u001b[0m  8.5010\n",
      "     42        \u001b[36m0.0019\u001b[0m        0.0078  8.4577\n",
      "     43        \u001b[36m0.0019\u001b[0m        0.0078  8.3809\n",
      "     44        0.0019        0.0079  8.3984\n",
      "     45        \u001b[36m0.0017\u001b[0m        \u001b[32m0.0078\u001b[0m  8.1974\n",
      "     46        0.0019        \u001b[32m0.0077\u001b[0m  8.2278\n",
      "     47        \u001b[36m0.0017\u001b[0m        0.0078  8.2359\n",
      "     48        \u001b[36m0.0016\u001b[0m        \u001b[32m0.0077\u001b[0m  8.1815\n",
      "     49        0.0018        0.0077  8.3675\n",
      "     50        0.0018        \u001b[32m0.0077\u001b[0m  8.3521\n",
      "     51        \u001b[36m0.0016\u001b[0m        \u001b[32m0.0076\u001b[0m  8.4401\n",
      "     52        \u001b[36m0.0016\u001b[0m        0.0076  8.2368\n",
      "     53        \u001b[36m0.0015\u001b[0m        0.0077  8.2547\n",
      "     54        \u001b[36m0.0014\u001b[0m        0.0077  8.2624\n",
      "     55        0.0016        0.0077  8.5274\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Best Parameters: {'lr': 1e-06, 'max_epochs': 200, 'module__dropout_rate': 0.01, 'optimizer': <class 'torch.optim.adam.Adam'>}\n",
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m-0.4787\u001b[0m       \u001b[32m-0.4476\u001b[0m  2.4985\n",
      "      2       \u001b[36m-0.4265\u001b[0m       \u001b[32m-0.4025\u001b[0m  2.4224\n",
      "      3       \u001b[36m-0.3803\u001b[0m       \u001b[32m-0.3608\u001b[0m  2.3729\n",
      "      4       \u001b[36m-0.3376\u001b[0m       \u001b[32m-0.3213\u001b[0m  2.3887\n",
      "      5       \u001b[36m-0.2968\u001b[0m       \u001b[32m-0.2835\u001b[0m  2.3478\n",
      "      6       \u001b[36m-0.2594\u001b[0m       \u001b[32m-0.2481\u001b[0m  2.2676\n",
      "      7       \u001b[36m-0.2250\u001b[0m       \u001b[32m-0.2166\u001b[0m  2.3693\n",
      "      8       \u001b[36m-0.1957\u001b[0m       \u001b[32m-0.1896\u001b[0m  2.4538\n",
      "      9       \u001b[36m-0.1707\u001b[0m       \u001b[32m-0.1668\u001b[0m  2.5124\n",
      "     10       \u001b[36m-0.1507\u001b[0m       \u001b[32m-0.1483\u001b[0m  2.2762\n",
      "     11       \u001b[36m-0.1347\u001b[0m       \u001b[32m-0.1331\u001b[0m  2.2670\n",
      "     12       \u001b[36m-0.1214\u001b[0m       \u001b[32m-0.1208\u001b[0m  2.3913\n",
      "     13       \u001b[36m-0.1112\u001b[0m       \u001b[32m-0.1104\u001b[0m  2.2647\n",
      "     14       \u001b[36m-0.1010\u001b[0m       \u001b[32m-0.1014\u001b[0m  2.3279\n",
      "     15       \u001b[36m-0.0941\u001b[0m       \u001b[32m-0.0933\u001b[0m  2.2803\n",
      "     16       \u001b[36m-0.0861\u001b[0m       \u001b[32m-0.0861\u001b[0m  2.3312\n",
      "     17       \u001b[36m-0.0792\u001b[0m       \u001b[32m-0.0796\u001b[0m  2.2323\n",
      "     18       \u001b[36m-0.0732\u001b[0m       \u001b[32m-0.0736\u001b[0m  2.3536\n",
      "     19       \u001b[36m-0.0671\u001b[0m       \u001b[32m-0.0681\u001b[0m  2.4916\n",
      "     20       \u001b[36m-0.0618\u001b[0m       \u001b[32m-0.0630\u001b[0m  2.2727\n",
      "     21       \u001b[36m-0.0567\u001b[0m       \u001b[32m-0.0583\u001b[0m  2.3819\n",
      "     22       \u001b[36m-0.0518\u001b[0m       \u001b[32m-0.0540\u001b[0m  2.2662\n",
      "     23       \u001b[36m-0.0477\u001b[0m       \u001b[32m-0.0501\u001b[0m  2.2719\n",
      "     24       \u001b[36m-0.0440\u001b[0m       \u001b[32m-0.0464\u001b[0m  2.2769\n",
      "     25       \u001b[36m-0.0406\u001b[0m       \u001b[32m-0.0431\u001b[0m  2.3287\n",
      "     26       \u001b[36m-0.0372\u001b[0m       \u001b[32m-0.0400\u001b[0m  2.5022\n",
      "     27       \u001b[36m-0.0346\u001b[0m       \u001b[32m-0.0372\u001b[0m  2.2764\n",
      "     28       \u001b[36m-0.0314\u001b[0m       \u001b[32m-0.0346\u001b[0m  2.3278\n",
      "     29       \u001b[36m-0.0295\u001b[0m       \u001b[32m-0.0323\u001b[0m  2.2905\n",
      "     30       \u001b[36m-0.0268\u001b[0m       \u001b[32m-0.0301\u001b[0m  2.4397\n",
      "     31       \u001b[36m-0.0249\u001b[0m       \u001b[32m-0.0282\u001b[0m  2.5012\n",
      "     32       \u001b[36m-0.0229\u001b[0m       \u001b[32m-0.0265\u001b[0m  2.4016\n",
      "     33       \u001b[36m-0.0209\u001b[0m       \u001b[32m-0.0249\u001b[0m  2.2958\n",
      "     34       \u001b[36m-0.0194\u001b[0m       \u001b[32m-0.0235\u001b[0m  2.2359\n",
      "     35       \u001b[36m-0.0182\u001b[0m       \u001b[32m-0.0221\u001b[0m  2.3351\n",
      "     36       \u001b[36m-0.0168\u001b[0m       \u001b[32m-0.0210\u001b[0m  2.2911\n",
      "     37       \u001b[36m-0.0159\u001b[0m       \u001b[32m-0.0199\u001b[0m  2.3743\n",
      "     38       \u001b[36m-0.0144\u001b[0m       \u001b[32m-0.0189\u001b[0m  2.2698\n",
      "     39       \u001b[36m-0.0136\u001b[0m       \u001b[32m-0.0180\u001b[0m  2.2987\n",
      "     40       \u001b[36m-0.0127\u001b[0m       \u001b[32m-0.0172\u001b[0m  2.3052\n",
      "     41       \u001b[36m-0.0117\u001b[0m       \u001b[32m-0.0165\u001b[0m  2.2605\n",
      "     42       \u001b[36m-0.0110\u001b[0m       \u001b[32m-0.0158\u001b[0m  2.4184\n",
      "     43       \u001b[36m-0.0105\u001b[0m       \u001b[32m-0.0152\u001b[0m  2.3308\n",
      "     44       \u001b[36m-0.0098\u001b[0m       \u001b[32m-0.0147\u001b[0m  2.3833\n",
      "     45       \u001b[36m-0.0090\u001b[0m       \u001b[32m-0.0142\u001b[0m  2.3651\n",
      "     46       \u001b[36m-0.0090\u001b[0m       \u001b[32m-0.0137\u001b[0m  2.5014\n",
      "     47       \u001b[36m-0.0080\u001b[0m       \u001b[32m-0.0133\u001b[0m  2.4126\n",
      "     48       \u001b[36m-0.0076\u001b[0m       \u001b[32m-0.0129\u001b[0m  2.2145\n",
      "     49       \u001b[36m-0.0072\u001b[0m       \u001b[32m-0.0126\u001b[0m  2.4664\n",
      "     50       \u001b[36m-0.0071\u001b[0m       \u001b[32m-0.0123\u001b[0m  2.3058\n",
      "     51       \u001b[36m-0.0065\u001b[0m       \u001b[32m-0.0120\u001b[0m  2.3608\n",
      "     52       \u001b[36m-0.0063\u001b[0m       \u001b[32m-0.0117\u001b[0m  2.3913\n",
      "     53       \u001b[36m-0.0061\u001b[0m       \u001b[32m-0.0115\u001b[0m  2.2769\n",
      "     54       \u001b[36m-0.0058\u001b[0m       \u001b[32m-0.0113\u001b[0m  2.3261\n",
      "     55       \u001b[36m-0.0055\u001b[0m       \u001b[32m-0.0111\u001b[0m  2.3254\n",
      "     56       \u001b[36m-0.0053\u001b[0m       \u001b[32m-0.0109\u001b[0m  2.2833\n",
      "     57       \u001b[36m-0.0050\u001b[0m       \u001b[32m-0.0107\u001b[0m  2.2863\n",
      "     58       \u001b[36m-0.0046\u001b[0m       \u001b[32m-0.0106\u001b[0m  2.3412\n",
      "     59       -0.0046       \u001b[32m-0.0104\u001b[0m  2.3394\n",
      "     60       \u001b[36m-0.0045\u001b[0m       \u001b[32m-0.0103\u001b[0m  2.3289\n",
      "     61       \u001b[36m-0.0044\u001b[0m       \u001b[32m-0.0102\u001b[0m  2.3242\n",
      "     62       -0.0044       \u001b[32m-0.0101\u001b[0m  2.3464\n",
      "     63       \u001b[36m-0.0040\u001b[0m       \u001b[32m-0.0100\u001b[0m  2.3255\n",
      "     64       -0.0042       \u001b[32m-0.0099\u001b[0m  2.3874\n",
      "     65       \u001b[36m-0.0038\u001b[0m       \u001b[32m-0.0099\u001b[0m  2.3139\n",
      "     66       \u001b[36m-0.0036\u001b[0m       \u001b[32m-0.0098\u001b[0m  2.3349\n",
      "     67       -0.0037       \u001b[32m-0.0098\u001b[0m  2.3533\n",
      "     68       -0.0039       \u001b[32m-0.0097\u001b[0m  2.2732\n",
      "     69       \u001b[36m-0.0035\u001b[0m       \u001b[32m-0.0096\u001b[0m  2.3093\n",
      "     70       -0.0036       \u001b[32m-0.0096\u001b[0m  2.3649\n",
      "     71       -0.0035       \u001b[32m-0.0095\u001b[0m  2.2430\n",
      "     72       \u001b[36m-0.0034\u001b[0m       \u001b[32m-0.0095\u001b[0m  2.2381\n",
      "     73       \u001b[36m-0.0032\u001b[0m       \u001b[32m-0.0095\u001b[0m  2.2156\n",
      "     74       -0.0033       \u001b[32m-0.0094\u001b[0m  2.1782\n",
      "     75       -0.0033       \u001b[32m-0.0094\u001b[0m  2.2316\n",
      "     76       \u001b[36m-0.0031\u001b[0m       \u001b[32m-0.0094\u001b[0m  2.2334\n",
      "     77       \u001b[36m-0.0031\u001b[0m       \u001b[32m-0.0094\u001b[0m  2.2125\n",
      "     78       \u001b[36m-0.0029\u001b[0m       \u001b[32m-0.0094\u001b[0m  2.1878\n",
      "     79       -0.0030       \u001b[32m-0.0093\u001b[0m  2.2218\n",
      "     80       \u001b[36m-0.0028\u001b[0m       \u001b[32m-0.0093\u001b[0m  2.1837\n",
      "     81       -0.0029       \u001b[32m-0.0093\u001b[0m  2.1996\n",
      "     82       -0.0029       \u001b[32m-0.0093\u001b[0m  2.2433\n",
      "     83       -0.0028       \u001b[32m-0.0092\u001b[0m  2.2324\n",
      "     84       -0.0029       \u001b[32m-0.0092\u001b[0m  2.2503\n",
      "     85       \u001b[36m-0.0027\u001b[0m       \u001b[32m-0.0092\u001b[0m  2.2377\n",
      "     86       -0.0027       \u001b[32m-0.0092\u001b[0m  2.2375\n",
      "     87       \u001b[36m-0.0026\u001b[0m       \u001b[32m-0.0092\u001b[0m  2.1768\n",
      "     88       \u001b[36m-0.0026\u001b[0m       \u001b[32m-0.0091\u001b[0m  2.2441\n",
      "     89       \u001b[36m-0.0025\u001b[0m       \u001b[32m-0.0091\u001b[0m  2.1817\n",
      "     90       -0.0027       \u001b[32m-0.0090\u001b[0m  2.2228\n",
      "     91       \u001b[36m-0.0024\u001b[0m       \u001b[32m-0.0090\u001b[0m  2.2330\n",
      "     92       -0.0025       \u001b[32m-0.0090\u001b[0m  2.2110\n",
      "     93       -0.0026       -0.0090  2.1915\n",
      "     94       -0.0026       -0.0090  2.1947\n",
      "     95       -0.0026       -0.0090  2.2438\n",
      "     96       -0.0026       -0.0090  2.1669\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Mean Squared Error: 0.003270376706495881\n",
      "R2 score: 0.18657195568084717\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#V3\n",
    "\n",
    "# Préparation des données\n",
    "print(\"Préparation des données...\")\n",
    "\n",
    "# Number of input features\n",
    "n_input_features = x_data_f.shape[1]\n",
    "\n",
    "# Define an enhanced neural network\n",
    "class EnhancedRegressionNet(nn.Module):\n",
    "    def __init__(self, n_input_features, dropout_rate, n_neurons=128):\n",
    "        super(EnhancedRegressionNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_input_features, n_neurons)  # n_input_features\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(n_neurons, n_neurons)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.fc3 = nn.Linear(n_neurons, 1)  # Output layer remains 2D\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x  # Do not squeeze the output; output remains shape [batch_size, 1]\n",
    "\n",
    "# Ensure both x_data_f and y_data_f are converted to float32\n",
    "x_data_f = x_data_f.astype(np.float32)  # Cast features to float32\n",
    "y_data_f = y_data_f.astype(np.float32)  # Cast target to float32\n",
    "\n",
    "# Define scoring callbacks for training and validation loss\n",
    "train_loss = EpochScoring(scoring='neg_mean_squared_error', on_train=True, name='train_loss', lower_is_better=False)\n",
    "valid_loss = EpochScoring(scoring='neg_mean_squared_error', name='valid_loss', lower_is_better=False)\n",
    "\n",
    "# Neural Network Regressor\n",
    "net = NeuralNetRegressor(\n",
    "    module=EnhancedRegressionNet,\n",
    "    module__n_input_features=n_input_features,  # n_input_features\n",
    "    criterion=nn.MSELoss,\n",
    "    optimizer=optim.Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    iterator_train__batch_size=32,\n",
    "    callbacks=[EarlyStopping(patience=5)],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'module__dropout_rate': [0.01],\n",
    "    'lr': [0.000001],\n",
    "    'max_epochs': [200],\n",
    "    'optimizer': [optim.Adam],\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(net, param_grid=param_grid, cv=KFold(n_splits=6), scoring='neg_mean_squared_error', n_jobs=2)\n",
    "\n",
    "# Ensure y_data_f has the correct shape (2D) for PyTorch\n",
    "y_data_f_reshaped = y_data_f.reshape(-1, 1)\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(x_data_f.values, y_data_f_reshaped)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Training of the model\n",
    "best_net = NeuralNetRegressor(\n",
    "    module=EnhancedRegressionNet,\n",
    "    module__n_input_features=n_input_features,\n",
    "    module__n_neurons=128,\n",
    "    module__dropout_rate=best_params['module__dropout_rate'],\n",
    "    criterion=nn.MSELoss,\n",
    "    max_epochs=best_params['max_epochs'],\n",
    "    optimizer=best_params['optimizer'],\n",
    "    lr=best_params['lr'],\n",
    "    iterator_train__shuffle=True,\n",
    "    callbacks=[EarlyStopping(patience=5), train_loss, valid_loss],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the final model\n",
    "best_net.fit(x_data_f.values, y_data_f_reshaped)\n",
    "\n",
    "# Predictions\n",
    "Y_pred = best_net.predict(x_data_f.values)\n",
    "\n",
    "# Reshape predictions for consistency (if needed)\n",
    "Y_pred = Y_pred.reshape(-1, 1)\n",
    "\n",
    "# Rescale predictions if necessary (using y_reverse, if required)\n",
    "Y_pred_rev = y_reverse(Y_pred)  # Uncomment if using y_reverse function\n",
    "\n",
    "# Create a DataFrame with predictions\n",
    "id_array = np.arange(1, len(Y_pred) + 1)\n",
    "final_df = pd.DataFrame({\n",
    "    'ID': id_array,\n",
    "    'division_rate': Y_pred_rev.flatten()\n",
    "})\n",
    "\n",
    "# Save the new DataFrame to a CSV file\n",
    "final_csv = final_df.to_csv(\"Data\\\\results_nn3.csv\", index=False)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_data_f_reshaped, Y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "r2 = r2_score(y_data_f_reshaped, Y_pred)\n",
    "print(f'R2 score: {r2}')\n",
    "\n",
    "# Extract training and validation loss for a plot\n",
    "train_losses = best_net.history[:, 'train_loss']\n",
    "valid_losses = best_net.history[:, 'valid_loss']\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(valid_losses, label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Negative Mean Squared Error')\n",
    "plt.title('Training and Validation Loss per Epoch')\n",
    "plt.legend()\n",
    "plt.savefig(\"Data\\\\NNplot_nn3.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Préparation des données...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 24 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n24 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\skorch\\regressor.py\", line 82, in fit\n    return super(NeuralNetRegressor, self).fit(X, y, **fit_params)\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\skorch\\net.py\", line 1319, in fit\n    self.partial_fit(X, y, **fit_params)\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\skorch\\net.py\", line 1278, in partial_fit\n    self.fit_loop(X, y, **fit_params)\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\skorch\\net.py\", line 1190, in fit_loop\n    self.run_single_epoch(iterator_train, training=True, prefix=\"train\",\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\skorch\\net.py\", line 1226, in run_single_epoch\n    step = step_fn(batch, **fit_params)\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\skorch\\net.py\", line 1105, in train_step\n    self._step_optimizer(step_fn)\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\skorch\\net.py\", line 1060, in _step_optimizer\n    optimizer.step(step_fn)\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\optim\\optimizer.py\", line 373, in wrapper\n    out = func(*args, **kwargs)\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\optim\\optimizer.py\", line 76, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\optim\\adam.py\", line 143, in step\n    loss = closure()\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\skorch\\net.py\", line 1094, in step_fn\n    step = self.train_step_single(batch, **fit_params)\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\skorch\\net.py\", line 995, in train_step_single\n    loss.backward()\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\_tensor.py\", line 492, in backward\n    torch.autograd.backward(\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\autograd\\__init__.py\", line 251, in backward\n    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\nRuntimeError: Found dtype Double but expected Float\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 60\u001b[0m\n\u001b[0;32m     54\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(net, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39mKFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m), scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# **Fix: Squeeze the target values to match the model output**\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m#y_data_f_squeezed = y_data_f.values.astype(np.float32).squeeze()  # Remove the last dimension\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Fit the grid search\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_data_f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_data_f\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Get the best parameters from the grid search\u001b[39;00m\n\u001b[0;32m     63\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1422\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1420\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    870\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    873\u001b[0m     )\n\u001b[1;32m--> 875\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m     )\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 24 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n24 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\skorch\\regressor.py\", line 82, in fit\n    return super(NeuralNetRegressor, self).fit(X, y, **fit_params)\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\skorch\\net.py\", line 1319, in fit\n    self.partial_fit(X, y, **fit_params)\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\skorch\\net.py\", line 1278, in partial_fit\n    self.fit_loop(X, y, **fit_params)\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\skorch\\net.py\", line 1190, in fit_loop\n    self.run_single_epoch(iterator_train, training=True, prefix=\"train\",\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\skorch\\net.py\", line 1226, in run_single_epoch\n    step = step_fn(batch, **fit_params)\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\skorch\\net.py\", line 1105, in train_step\n    self._step_optimizer(step_fn)\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\skorch\\net.py\", line 1060, in _step_optimizer\n    optimizer.step(step_fn)\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\optim\\optimizer.py\", line 373, in wrapper\n    out = func(*args, **kwargs)\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\optim\\optimizer.py\", line 76, in _use_grad\n    ret = func(self, *args, **kwargs)\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\optim\\adam.py\", line 143, in step\n    loss = closure()\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\skorch\\net.py\", line 1094, in step_fn\n    step = self.train_step_single(batch, **fit_params)\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\skorch\\net.py\", line 995, in train_step_single\n    loss.backward()\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\_tensor.py\", line 492, in backward\n    torch.autograd.backward(\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\autograd\\__init__.py\", line 251, in backward\n    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\nRuntimeError: Found dtype Double but expected Float\n"
     ]
    }
   ],
   "source": [
    "#V2\n",
    "\n",
    "# Préparation des données\n",
    "print(\"Préparation des données...\")\n",
    "\n",
    "# Number of input features\n",
    "n_input_features = x_data_f.shape[1]\n",
    "\n",
    "# Define an enhanced neural network\n",
    "class EnhancedRegressionNet(nn.Module):\n",
    "    def __init__(self, n_input_features, dropout_rate, n_neurons=128):\n",
    "        super(EnhancedRegressionNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_input_features, n_neurons)  # n_input_features\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(n_neurons, n_neurons)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.fc3 = nn.Linear(n_neurons, 1)  # Output layer remains 2D\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x  # Do not squeeze the output; output remains shape [batch_size, 1]\n",
    "\n",
    "# Define scoring callbacks for training and validation loss\n",
    "train_loss = EpochScoring(scoring='neg_mean_squared_error', on_train=True, name='train_loss', lower_is_better=False)\n",
    "valid_loss = EpochScoring(scoring='neg_mean_squared_error', name='valid_loss', lower_is_better=False)\n",
    "\n",
    "# Neural Network Regressor\n",
    "net = NeuralNetRegressor(\n",
    "    module=EnhancedRegressionNet,\n",
    "    module__n_input_features=n_input_features,  # n_input_features\n",
    "    criterion=nn.MSELoss,\n",
    "    optimizer=optim.Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    iterator_train__batch_size=32,\n",
    "    callbacks=[EarlyStopping(patience=5)],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    'module__dropout_rate': [0.011, 0.012],\n",
    "    'lr': [0.00015, 0.00017],\n",
    "    'max_epochs': [20],\n",
    "    'optimizer': [optim.Adam],\n",
    "}\n",
    "\n",
    "# GridSearchCV\n",
    "grid_search = GridSearchCV(net, param_grid=param_grid, cv=KFold(n_splits=6), scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# **Fix: Squeeze the target values to match the model output**\n",
    "#y_data_f_squeezed = y_data_f.values.astype(np.float32).squeeze()  # Remove the last dimension\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(x_data_f.values.astype(np.float32), y_data_f)\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Training of the model\n",
    "best_net = NeuralNetRegressor(\n",
    "    module=EnhancedRegressionNet,\n",
    "    module__n_input_features=n_input_features,\n",
    "    module__n_neurons=128,\n",
    "    module__dropout_rate=best_params['module__dropout_rate'],\n",
    "    criterion=nn.MSELoss,\n",
    "    max_epochs=best_params['max_epochs'],\n",
    "    optimizer=best_params['optimizer'],\n",
    "    lr=best_params['lr'],\n",
    "    iterator_train__shuffle=True,\n",
    "    callbacks=[EarlyStopping(patience=5), train_loss, valid_loss],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# **Use the squeezed target values for training**\n",
    "best_net.fit(x_data_f.values.astype(np.float32), y_data_f)\n",
    "\n",
    "# Predictions\n",
    "Y_pred = best_net.predict(x_data_f.values.astype(np.float32))\n",
    "\n",
    "# Fix: Ensure predictions are reshaped for consistency if needed\n",
    "Y_pred = Y_pred.reshape(-1, 1)  \n",
    "Y_pred_rev = y_reverse(Y_pred)\n",
    "\n",
    "# Create a DataFrame with predictions\n",
    "id_array = np.arange(1, len(Y_pred) + 1)\n",
    "final_df = pd.DataFrame({\n",
    "    'ID': id_array,\n",
    "    'division_rate': Y_pred.flatten()\n",
    "})\n",
    "\n",
    "# Save the new DataFrame to a CSV file\n",
    "final_csv = final_df.to_csv(\"Data\\\\results_nn3.csv\", index=False)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_data_f, Y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "r2 = r2_score(y_data_f, Y_pred)\n",
    "print(f'R2 score: {r2}')\n",
    "\n",
    "# Extract training and validation loss for a plot\n",
    "train_losses = best_net.history[:, 'train_loss']\n",
    "valid_losses = best_net.history[:, 'valid_loss']\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(valid_losses, label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Negative Mean Squared Error')\n",
    "plt.title('Training and Validation Loss per Epoch')\n",
    "plt.legend()\n",
    "plt.savefig(\"Data\\\\NNplot_nn3.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Préparation des données...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([25, 1])) that is different to the input size (torch.Size([25])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m0.0739\u001b[0m        \u001b[32m0.0866\u001b[0m  7.3849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([128, 1])) that is different to the input size (torch.Size([128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([31, 1])) that is different to the input size (torch.Size([31])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2        \u001b[36m0.0689\u001b[0m        \u001b[32m0.0854\u001b[0m  6.8601\n",
      "      3        \u001b[36m0.0466\u001b[0m        \u001b[32m0.0844\u001b[0m  6.7317\n",
      "      4        \u001b[36m0.0457\u001b[0m        0.0847  7.0510\n",
      "      5        \u001b[36m0.0440\u001b[0m        0.0852  6.6748\n",
      "      6        \u001b[36m0.0437\u001b[0m        0.0846  6.4815\n",
      "      7        \u001b[36m0.0433\u001b[0m        \u001b[32m0.0842\u001b[0m  6.3643\n",
      "      8        \u001b[36m0.0428\u001b[0m        \u001b[32m0.0840\u001b[0m  6.1194\n",
      "      9        0.0431        0.0844  6.5441\n",
      "     10        0.0430        0.0843  6.4121\n",
      "     11        \u001b[36m0.0427\u001b[0m        0.0841  6.1285\n",
      "     12        \u001b[36m0.0425\u001b[0m        0.0843  5.8971\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Best Parameters: {'lr': 0.00015, 'max_epochs': 20, 'module__dropout_rate': 0.011, 'optimizer': <class 'torch.optim.adam.Adam'>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([121, 1])) that is different to the input size (torch.Size([121])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m-0.2971\u001b[0m       \u001b[32m-0.0882\u001b[0m  2.3836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([128, 1])) that is different to the input size (torch.Size([128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([121, 1])) that is different to the input size (torch.Size([121])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2       \u001b[36m-0.0453\u001b[0m       \u001b[32m-0.0857\u001b[0m  2.2393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([31, 1])) that is different to the input size (torch.Size([31])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([128, 1])) that is different to the input size (torch.Size([128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([121, 1])) that is different to the input size (torch.Size([121])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3       -0.0524       \u001b[32m-0.0848\u001b[0m  2.2999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([31, 1])) that is different to the input size (torch.Size([31])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([128, 1])) that is different to the input size (torch.Size([128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([121, 1])) that is different to the input size (torch.Size([121])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4       -0.0489       -0.0867  2.1769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([31, 1])) that is different to the input size (torch.Size([31])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([128, 1])) that is different to the input size (torch.Size([128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([121, 1])) that is different to the input size (torch.Size([121])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5       -0.0485       -0.0850  2.1170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([31, 1])) that is different to the input size (torch.Size([31])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([128, 1])) that is different to the input size (torch.Size([128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([121, 1])) that is different to the input size (torch.Size([121])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6       -0.0458       -0.0851  2.1845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([31, 1])) that is different to the input size (torch.Size([31])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([128, 1])) that is different to the input size (torch.Size([128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([121, 1])) that is different to the input size (torch.Size([121])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7       -0.0459       \u001b[32m-0.0842\u001b[0m  2.1675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([31, 1])) that is different to the input size (torch.Size([31])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([128, 1])) that is different to the input size (torch.Size([128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([121, 1])) that is different to the input size (torch.Size([121])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8       \u001b[36m-0.0448\u001b[0m       -0.0847  2.2306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([31, 1])) that is different to the input size (torch.Size([31])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([128, 1])) that is different to the input size (torch.Size([128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([121, 1])) that is different to the input size (torch.Size([121])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9       -0.0454       \u001b[32m-0.0836\u001b[0m  2.2131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([31, 1])) that is different to the input size (torch.Size([31])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([128, 1])) that is different to the input size (torch.Size([128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([121, 1])) that is different to the input size (torch.Size([121])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10       \u001b[36m-0.0447\u001b[0m       \u001b[32m-0.0834\u001b[0m  2.1883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([31, 1])) that is different to the input size (torch.Size([31])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([128, 1])) that is different to the input size (torch.Size([128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([121, 1])) that is different to the input size (torch.Size([121])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     11       \u001b[36m-0.0434\u001b[0m       -0.0835  2.2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([31, 1])) that is different to the input size (torch.Size([31])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([128, 1])) that is different to the input size (torch.Size([128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([121, 1])) that is different to the input size (torch.Size([121])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     12       -0.0441       -0.0849  2.1438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([31, 1])) that is different to the input size (torch.Size([31])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([128, 1])) that is different to the input size (torch.Size([128])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([121, 1])) that is different to the input size (torch.Size([121])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([31, 1])) that is different to the input size (torch.Size([31])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "Mean Squared Error: 0.05053408454815331\n",
      "R2 score: -0.007672996479935579\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 118\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minspection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m permutation_importance\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# Calculate permutation importance\u001b[39;00m\n\u001b[1;32m--> 118\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mpermutation_importance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbest_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Trained model\u001b[39;49;00m\n\u001b[0;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_data_f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Input data\u001b[39;49;00m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_data_f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Target values\u001b[39;49;00m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mneg_mean_squared_error\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Scoring metric\u001b[39;49;00m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Number of permutations\u001b[39;49;00m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# For reproducibility\u001b[39;49;00m\n\u001b[0;32m    125\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# Create a DataFrame for feature importance\u001b[39;00m\n\u001b[0;32m    128\u001b[0m feature_importances \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m\"\u001b[39m: x_data_f\u001b[38;5;241m.\u001b[39mcolumns,\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m\"\u001b[39m: results\u001b[38;5;241m.\u001b[39mimportances_mean\n\u001b[0;32m    131\u001b[0m })\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\inspection\\_permutation_importance.py:289\u001b[0m, in \u001b[0;36mpermutation_importance\u001b[1;34m(estimator, X, y, scoring, n_repeats, n_jobs, random_state, sample_weight, max_samples)\u001b[0m\n\u001b[0;32m    285\u001b[0m     scorer \u001b[38;5;241m=\u001b[39m _MultimetricScorer(scorers\u001b[38;5;241m=\u001b[39mscorers_dict)\n\u001b[0;32m    287\u001b[0m baseline_score \u001b[38;5;241m=\u001b[39m _weights_scorer(scorer, estimator, X, y, sample_weight)\n\u001b[1;32m--> 289\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_calculate_permutation_scores\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(baseline_score, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    306\u001b[0m         name: _create_importances_bunch(\n\u001b[0;32m    307\u001b[0m             baseline_score[name],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m baseline_score\n\u001b[0;32m    312\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\inspection\\_permutation_importance.py:70\u001b[0m, in \u001b[0;36m_calculate_permutation_scores\u001b[1;34m(estimator, X, y, sample_weight, col_idx, random_state, n_repeats, scorer, max_samples)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m         X_permuted[:, col_idx] \u001b[38;5;241m=\u001b[39m X_permuted[shuffling_idx, col_idx]\n\u001b[1;32m---> 70\u001b[0m     scores\u001b[38;5;241m.\u001b[39mappend(\u001b[43m_weights_scorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_permuted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scores[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m     73\u001b[0m     scores \u001b[38;5;241m=\u001b[39m _aggregate_score_dicts(scores)\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\inspection\\_permutation_importance.py:25\u001b[0m, in \u001b[0;36m_weights_scorer\u001b[1;34m(scorer, estimator, X, y, sample_weight)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m scorer(estimator, X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:266\u001b[0m, in \u001b[0;36m_BaseScorer.__call__\u001b[1;34m(self, estimator, X, y_true, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    264\u001b[0m     _kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample_weight\n\u001b[1;32m--> 266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_score(partial(_cached_call, \u001b[38;5;28;01mNone\u001b[39;00m), estimator, X, y_true, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:353\u001b[0m, in \u001b[0;36m_PredictScorer._score\u001b[1;34m(self, method_caller, estimator, X, y_true, **kwargs)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate predicted target values for X relative to y_true.\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \n\u001b[0;32m    318\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;124;03m    Score function applied to prediction of estimator on X.\u001b[39;00m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_overlap(\n\u001b[0;32m    346\u001b[0m     message\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    347\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere is an overlap between set kwargs of this scorer instance and\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    351\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m    352\u001b[0m )\n\u001b[1;32m--> 353\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmethod_caller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    354\u001b[0m scoring_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sign \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_score_func(y_true, y_pred, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscoring_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:86\u001b[0m, in \u001b[0;36m_cached_call\u001b[1;34m(cache, estimator, response_method, *args, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m response_method \u001b[38;5;129;01min\u001b[39;00m cache:\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cache[response_method]\n\u001b[1;32m---> 86\u001b[0m result, _ \u001b[38;5;241m=\u001b[39m _get_response_values(\n\u001b[0;32m     87\u001b[0m     estimator, \u001b[38;5;241m*\u001b[39margs, response_method\u001b[38;5;241m=\u001b[39mresponse_method, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m     88\u001b[0m )\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     cache[response_method] \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\utils\\_response.py:218\u001b[0m, in \u001b[0;36m_get_response_values\u001b[1;34m(estimator, X, response_method, pos_label)\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response_method \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    213\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should either be a classifier to be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    214\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mused with response_method=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or the response_method \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    215\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Got a regressor with response_method=\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    216\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse_method\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    217\u001b[0m         )\n\u001b[1;32m--> 218\u001b[0m     y_pred, pos_label \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_pred, pos_label\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\skorch\\net.py:1632\u001b[0m, in \u001b[0;36mNeuralNet.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1602\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m   1603\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Where applicable, return class labels for samples in X.\u001b[39;00m\n\u001b[0;32m   1604\u001b[0m \n\u001b[0;32m   1605\u001b[0m \u001b[38;5;124;03m    If the module's forward method returns multiple outputs as a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1630\u001b[0m \n\u001b[0;32m   1631\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1632\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\skorch\\net.py:1595\u001b[0m, in \u001b[0;36mNeuralNet.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1593\u001b[0m nonlin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_predict_nonlinearity()\n\u001b[0;32m   1594\u001b[0m y_probas \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1595\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m yp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_iter(X, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   1596\u001b[0m     yp \u001b[38;5;241m=\u001b[39m yp[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(yp, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m yp\n\u001b[0;32m   1597\u001b[0m     yp \u001b[38;5;241m=\u001b[39m nonlin(yp)\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\skorch\\net.py:1440\u001b[0m, in \u001b[0;36mNeuralNet.forward_iter\u001b[1;34m(self, X, training, device)\u001b[0m\n\u001b[0;32m   1438\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_dataset(X)\n\u001b[0;32m   1439\u001b[0m iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(dataset, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[1;32m-> 1440\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m iterator:\n\u001b[0;32m   1441\u001b[0m     yp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_step(batch, training\u001b[38;5;241m=\u001b[39mtraining)\n\u001b[0;32m   1442\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m to_device(yp, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    139\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:171\u001b[0m, in \u001b[0;36mcollate_numpy_array_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern\u001b[38;5;241m.\u001b[39msearch(elem\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#V1\n",
    "# Préparation des données\n",
    "print(\"Préparation des données...\")\n",
    "\n",
    "# Number of input features\n",
    "n_input_features = x_data_f.shape[1]\n",
    "\n",
    "# Define an enhanced neural network\n",
    "class EnhancedRegressionNet(nn.Module):\n",
    "    def __init__(self, n_input_features, dropout_rate, n_neurons=128):\n",
    "        super(EnhancedRegressionNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_input_features, n_neurons) #n_input_features\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(n_neurons, n_neurons)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "        self.fc3 = nn.Linear(n_neurons, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x.squeeze()\n",
    "\n",
    "\n",
    "# Define scoring callbacks for training and validation loss\n",
    "train_loss = EpochScoring(scoring='neg_mean_squared_error', on_train=True, name='train_loss', lower_is_better=False)\n",
    "valid_loss = EpochScoring(scoring='neg_mean_squared_error', name='valid_loss', lower_is_better=False)\n",
    "\n",
    "\n",
    "#Neural Network Regressor\n",
    "net = NeuralNetRegressor(\n",
    "    module=EnhancedRegressionNet,\n",
    "    module__n_input_features=n_input_features , #n_input_features\n",
    "    criterion=nn.MSELoss,\n",
    "    optimizer=optim.Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    iterator_train__batch_size = 32,\n",
    "    callbacks=[EarlyStopping(patience=5)],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "#parameter grid\n",
    "param_grid = {\n",
    "    'module__dropout_rate': [0.011, 0.012],\n",
    "    'lr': [0.00015, 0.00017],\n",
    "    'max_epochs': [20],\n",
    "    'optimizer': [optim.Adam],\n",
    "}\n",
    "\n",
    "\n",
    "# GridSearchCV \n",
    "grid_search = GridSearchCV(net, param_grid=param_grid, cv=KFold(n_splits=6), scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(x_data_f.values.astype(np.float32), y_data_f.values.astype(np.float32))\n",
    "\n",
    "# Get the best parameters from the grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Training of the model\n",
    "best_net = NeuralNetRegressor(\n",
    "    module=EnhancedRegressionNet,\n",
    "    module__n_input_features=n_input_features,\n",
    "    module__n_neurons=128,\n",
    "    module__dropout_rate=best_params['module__dropout_rate'],\n",
    "    criterion=nn.MSELoss,\n",
    "    max_epochs=best_params['max_epochs'],\n",
    "    optimizer=best_params['optimizer'],\n",
    "    lr=best_params['lr'],\n",
    "    iterator_train__shuffle=True,\n",
    "    callbacks=[EarlyStopping(patience=5), train_loss, valid_loss],\n",
    "    verbose=1\n",
    ")\n",
    "best_net.fit(x_data_f.values.astype(np.float32), y_data_f.values.astype(np.float32))\n",
    "\n",
    "Y_pred = best_net.predict(x_data_f.values.astype(np.float32))\n",
    "\n",
    "id_array = np.arange(1, len(Y_pred)+1)\n",
    "final_df = pd.DataFrame({\n",
    "    'ID': id_array,\n",
    "    'division_rate': Y_pred.flatten()\n",
    "})\n",
    "\n",
    "#pour que ça run tout en même temps\n",
    "mse = mean_squared_error(y_data_f, Y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "r2 = r2_score(y_data_f, Y_pred)\n",
    "print(f'R2 score: {r2}')\n",
    "\n",
    "# Save the new DataFrame to a CSV file\n",
    "final_csv = final_df.to_csv(\"Data\\\\results_nn3.csv\", index=False)\n",
    "\n",
    "# Extract training and validation loss for a plot\n",
    "train_losses = best_net.history[:, 'train_loss']\n",
    "valid_losses = best_net.history[:, 'valid_loss']\n",
    "\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(valid_losses, label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Negative Mean Squared Error')\n",
    "plt.title('Training and Validation Loss per Epoch')\n",
    "plt.legend()\n",
    "plt.savefig(\"Data\\\\NNplot_nn3.png\")\n",
    "\n",
    "'''\n",
    "In a neural network, you don't directly get \"feature importances\" like in tree-based models (e.g., Random Forest or XGBoost). \n",
    "However, you can estimate feature importance by analyzing how sensitive the model's predictions are to changes in each feature. \n",
    "This method is often referred to as \"permutation importance\" or \"feature sensitivity analysis.\"\n",
    "\n",
    "Here's a Python script to compute and visualize the top 10 most important features based on permutation importance:\n",
    "'''\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Calculate permutation importance\n",
    "results = permutation_importance(\n",
    "    best_net,  # Trained model\n",
    "    x_data_f.values.astype(np.float32),  # Input data\n",
    "    y_data_f.values.astype(np.float32),  # Target values\n",
    "    scoring=\"neg_mean_squared_error\",  # Scoring metric\n",
    "    n_repeats=10,  # Number of permutations\n",
    "    random_state=42  # For reproducibility\n",
    ")\n",
    "\n",
    "# Create a DataFrame for feature importance\n",
    "feature_importances = pd.DataFrame({\n",
    "    \"Feature\": x_data_f.columns,\n",
    "    \"Importance\": results.importances_mean\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Select the top 10 features\n",
    "top_10_features = feature_importances.head(10)\n",
    "\n",
    "# Plot the top 10 features\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_10_features[\"Feature\"], top_10_features[\"Importance\"], align=\"center\")\n",
    "plt.gca().invert_yaxis()  # Highest importance on top\n",
    "plt.xlabel(\"Mean Importance\")\n",
    "plt.title(\"Top 10 Most Important Features\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Data\\\\Feature_Importance_Plot.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_deprecate_Xt_in_inverse_transform' from 'sklearn.utils.deprecation' (c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\utils\\deprecation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#imporatnces with SHAP\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\shap\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_explanation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Cohorts, Explanation\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# explainers\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplainers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m other\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplainers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_additive\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AdditiveExplainer\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplainers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_deep\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeepExplainer\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\shap\\explainers\\__init__.py:4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_deep\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeepExplainer\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_exact\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExactExplainer\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_gpu_tree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPUTreeExplainer\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_gradient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradientExplainer\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_kernel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KernelExplainer\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\shap\\explainers\\_gpu_tree.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m assert_import, record_import_error\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_tree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      6\u001b[0m     TreeExplainer,\n\u001b[0;32m      7\u001b[0m     _xgboost_cat_unsupported,\n\u001b[0;32m      8\u001b[0m     feature_perturbation_codes,\n\u001b[0;32m      9\u001b[0m     output_transform_codes,\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _cext_gpu\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\shap\\explainers\\_tree.py:24\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m assert_import, record_import_error, safe_isinstance\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_exceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     18\u001b[0m     DimensionError,\n\u001b[0;32m     19\u001b[0m     ExplainerError,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     22\u001b[0m     InvalidModelError,\n\u001b[0;32m     23\u001b[0m )\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_legacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DenseData\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_explainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Explainer\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mother\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ubjson\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decode_ubjson_buffer\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\shap\\utils\\_legacy.py:6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMeans\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimpute\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleImputer\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkmeans\u001b[39m(X, k, round_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\cluster\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"Popular unsupervised clustering algorithms.\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_affinity_propagation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AffinityPropagation, affinity_propagation\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_agglomerative\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m     AgglomerativeClustering,\n\u001b[0;32m      6\u001b[0m     FeatureAgglomeration,\n\u001b[0;32m      7\u001b[0m     linkage_tree,\n\u001b[0;32m      8\u001b[0m     ward_tree,\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bicluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SpectralBiclustering, SpectralCoclustering\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_birch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Birch\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\cluster\\_agglomerative.py:42\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# mypy error: Module 'sklearn.cluster' has no attribute '_hierarchical_fast'\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _hierarchical_fast \u001b[38;5;28;01mas\u001b[39;00m _hierarchical  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_feature_agglomeration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AgglomerationTransform\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# For non fully-connected graphs\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fix_connectivity\u001b[39m(X, connectivity, affinity):\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\cluster\\_feature_agglomeration.py:15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TransformerMixin\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metadata_routing\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _deprecate_Xt_in_inverse_transform\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_is_fitted\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Mixin class for feature agglomeration.\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_deprecate_Xt_in_inverse_transform' from 'sklearn.utils.deprecation' (c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\utils\\deprecation.py)"
     ]
    }
   ],
   "source": [
    "#imporatnces with SHAP\n",
    "\n",
    "import shap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create SHAP explainer\n",
    "explainer = shap.DeepExplainer(best_net, x_data_f.values.astype(np.float32))\n",
    "\n",
    "# Initialize an array to store SHAP values\n",
    "shap_values = []\n",
    "\n",
    "# Progress bar\n",
    "with tqdm(total=len(x_data_f), desc=\"Computing SHAP Values\") as pbar:\n",
    "    for i in range(len(x_data_f)):\n",
    "        shap_value = explainer.shap_values(x_data_f.values[i:i+1].astype(np.float32))  # Compute SHAP for one sample\n",
    "        shap_values.append(shap_value[0])  # SHAP for the first output class\n",
    "        pbar.update(1)\n",
    "\n",
    "# Convert SHAP values to a numpy array\n",
    "shap_values = np.vstack(shap_values)\n",
    "\n",
    "# Summarize feature importance\n",
    "feature_importances = pd.DataFrame({\n",
    "    \"Feature\": x_data_f.columns,\n",
    "    \"Importance\": np.abs(shap_values).mean(axis=0)  # Mean absolute SHAP values\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Select the top 10 features\n",
    "top_10_features = feature_importances.head(10)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 9))\n",
    "plt.barh(top_10_features[\"Feature\"], top_10_features[\"Importance\"], align=\"center\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Mean Absolute SHAP Values\")\n",
    "plt.title(\"Top 10 Most Important Features (SHAP)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Data\\\\SHAP_Feature_Importance_Plot.png\")\n",
    "plt.show()\n",
    "\n",
    "# Display top 10 features\n",
    "print(top_10_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Integrated Gradients:   0%|          | 0/792 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "<class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n  module_=EnhancedRegressionNet(\n    (fc1): Linear(in_features=334898, out_features=128, bias=True)\n    (relu1): ReLU()\n    (dropout1): Dropout(p=0.012, inplace=False)\n    (fc2): Linear(in_features=128, out_features=128, bias=True)\n    (relu2): ReLU()\n    (dropout2): Dropout(p=0.012, inplace=False)\n    (fc3): Linear(in_features=128, out_features=1, bias=True)\n  ),\n) is not a callable object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(x_tensor), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputing Integrated Gradients\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(x_tensor)):\n\u001b[1;32m---> 21\u001b[0m         attr, _ \u001b[38;5;241m=\u001b[39m \u001b[43mig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_tensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_convergence_delta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Compute IG for one sample\u001b[39;00m\n\u001b[0;32m     22\u001b[0m         attributions\u001b[38;5;241m.\u001b[39mappend(attr\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     23\u001b[0m         pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\captum\\log\\__init__.py:42\u001b[0m, in \u001b[0;36mlog_usage.<locals>._log_usage.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\captum\\attr\\_core\\integrated_gradients.py:286\u001b[0m, in \u001b[0;36mIntegratedGradients.attribute\u001b[1;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001b[0m\n\u001b[0;32m    274\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m _batch_attribution(\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    276\u001b[0m         num_examples,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    283\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    284\u001b[0m     )\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 286\u001b[0m     attributions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attribute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbaselines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaselines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_convergence_delta:\n\u001b[0;32m    296\u001b[0m     start_point, end_point \u001b[38;5;241m=\u001b[39m baselines, inputs\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\captum\\attr\\_core\\integrated_gradients.py:351\u001b[0m, in \u001b[0;36mIntegratedGradients._attribute\u001b[1;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, step_sizes_and_alphas)\u001b[0m\n\u001b[0;32m    348\u001b[0m expanded_target \u001b[38;5;241m=\u001b[39m _expand_target(target, n_steps)\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# grads: dim -> (bsz * #steps x inputs[0].shape[1:], ...)\u001b[39;00m\n\u001b[1;32m--> 351\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaled_features_tpl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_ind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpanded_target\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_additional_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;66;03m# flattening grads so that we can multilpy it with step-size\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;66;03m# calling contiguous to avoid `memory whole` problems\u001b[39;00m\n\u001b[0;32m    360\u001b[0m scaled_grads \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    361\u001b[0m     grad\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(n_steps, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(step_sizes)\u001b[38;5;241m.\u001b[39mview(n_steps, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(grad\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m grad \u001b[38;5;129;01min\u001b[39;00m grads\n\u001b[0;32m    364\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\captum\\_utils\\gradient.py:112\u001b[0m, in \u001b[0;36mcompute_gradients\u001b[1;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03mComputes gradients of the output with respect to inputs for an\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03marbitrary forward function.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m                arguments) if no additional arguments are required\u001b[39;00m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;66;03m# runs forward pass\u001b[39;00m\n\u001b[1;32m--> 112\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43m_run_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforward_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_ind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional_forward_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, (\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget not provided when necessary, cannot\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m take gradient with respect to multiple outputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    116\u001b[0m     )\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# torch.unbind(forward_out) is a list of scalar tensor tuples and\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# contains batch_size * #steps elements\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\captum\\_utils\\common.py:521\u001b[0m, in \u001b[0;36m_run_forward\u001b[1;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_forward\u001b[39m(\n\u001b[0;32m    516\u001b[0m     forward_func: Callable,\n\u001b[0;32m    517\u001b[0m     inputs: Any,\n\u001b[0;32m    518\u001b[0m     target: TargetType \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    519\u001b[0m     additional_forward_args: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    520\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 521\u001b[0m     forward_func_args \u001b[38;5;241m=\u001b[39m \u001b[43msignature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforward_func\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mparameters\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(forward_func_args) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    523\u001b[0m         output \u001b[38;5;241m=\u001b[39m forward_func()\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\inspect.py:3254\u001b[0m, in \u001b[0;36msignature\u001b[1;34m(obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[0;32m   3252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msignature\u001b[39m(obj, \u001b[38;5;241m*\u001b[39m, follow_wrapped\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   3253\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get a signature object for the passed callable.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 3254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_wrapped\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3255\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\inspect.py:3002\u001b[0m, in \u001b[0;36mSignature.from_callable\u001b[1;34m(cls, obj, follow_wrapped, globals, locals, eval_str)\u001b[0m\n\u001b[0;32m   2998\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   2999\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_callable\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   3000\u001b[0m                   follow_wrapped\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28mlocals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, eval_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m   3001\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 3002\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_signature_from_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigcls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3003\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mfollow_wrapper_chains\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_wrapped\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3004\u001b[0m \u001b[43m                                    \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\inspect.py:2396\u001b[0m, in \u001b[0;36m_signature_from_callable\u001b[1;34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001b[0m\n\u001b[0;32m   2387\u001b[0m _get_signature_of \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(_signature_from_callable,\n\u001b[0;32m   2388\u001b[0m                             follow_wrapper_chains\u001b[38;5;241m=\u001b[39mfollow_wrapper_chains,\n\u001b[0;32m   2389\u001b[0m                             skip_bound_arg\u001b[38;5;241m=\u001b[39mskip_bound_arg,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2392\u001b[0m                             sigcls\u001b[38;5;241m=\u001b[39msigcls,\n\u001b[0;32m   2393\u001b[0m                             eval_str\u001b[38;5;241m=\u001b[39meval_str)\n\u001b[0;32m   2395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(obj):\n\u001b[1;32m-> 2396\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m is not a callable object\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj))\n\u001b[0;32m   2398\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, types\u001b[38;5;241m.\u001b[39mMethodType):\n\u001b[0;32m   2399\u001b[0m     \u001b[38;5;66;03m# In this case we skip the first parameter of the underlying\u001b[39;00m\n\u001b[0;32m   2400\u001b[0m     \u001b[38;5;66;03m# function (usually `self` or `cls`).\u001b[39;00m\n\u001b[0;32m   2401\u001b[0m     sig \u001b[38;5;241m=\u001b[39m _get_signature_of(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: <class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n  module_=EnhancedRegressionNet(\n    (fc1): Linear(in_features=334898, out_features=128, bias=True)\n    (relu1): ReLU()\n    (dropout1): Dropout(p=0.012, inplace=False)\n    (fc2): Linear(in_features=128, out_features=128, bias=True)\n    (relu2): ReLU()\n    (dropout2): Dropout(p=0.012, inplace=False)\n    (fc3): Linear(in_features=128, out_features=1, bias=True)\n  ),\n) is not a callable object"
     ]
    }
   ],
   "source": [
    "#importances with captum\n",
    "\n",
    "import torch\n",
    "from captum.attr import IntegratedGradients\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "x_tensor = torch.tensor(x_data_f.values.astype(np.float32))\n",
    "y_tensor = torch.tensor(y_data_f.astype(np.float32))\n",
    "\n",
    "# Initialize Integrated Gradients\n",
    "ig = IntegratedGradients(best_net)\n",
    "\n",
    "# Initialize an array to store attributions\n",
    "attributions = []\n",
    "\n",
    "# Progress bar\n",
    "with tqdm(total=len(x_tensor), desc=\"Computing Integrated Gradients\") as pbar:\n",
    "    for i in range(len(x_tensor)):\n",
    "        attr, _ = ig.attribute(x_tensor[i:i+1], target=0, return_convergence_delta=True)  # Compute IG for one sample\n",
    "        attributions.append(attr.detach().numpy())\n",
    "        pbar.update(1)\n",
    "\n",
    "# Aggregate absolute values of attributions across samples for each feature\n",
    "attributions = np.vstack(attributions)\n",
    "feature_importances = np.abs(attributions).mean(axis=0)\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    \"Feature\": x_data_f.columns,\n",
    "    \"Importance\": feature_importances\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Select the top 10 features\n",
    "top_10_features = feature_importance_df.head(10)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 9))\n",
    "plt.barh(top_10_features[\"Feature\"], top_10_features[\"Importance\"], align=\"center\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Integrated Gradients Importance\")\n",
    "plt.title(\"Top 10 Most Important Features (Captum)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Data\\\\Captum_Feature_Importance_Plot.png\")\n",
    "plt.show()\n",
    "\n",
    "# Display top 10 features\n",
    "print(top_10_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "BrokenProcessPool",
     "evalue": "A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 426, in _process_worker\n    call_item = call_queue.get(block=True, timeout=timeout)\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\multiprocessing\\queues.py\", line 122, in get\n    return _ForkingPickler.loads(res)\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\skorch\\net.py\", line 2231, in __setstate__\n    cuda_attrs = torch.load(f, **load_kwargs)\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\serialization.py\", line 1025, in load\n    return _load(opened_zipfile,\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\serialization.py\", line 1446, in _load\n    result = unpickler.load()\n  File \"c:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\torch\\serialization.py\", line 1439, in find_class\n    return super().find_class(mod_name, name)\nAttributeError: Can't get attribute 'EnhancedRegressionNet' on <module '__main__' (built-in)>\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minspection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m permutation_importance\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Calculate permutation importance\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mpermutation_importance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbest_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Trained model\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_data_f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Input data\u001b[39;49;00m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_data_f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Target values\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mneg_mean_squared_error\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Scoring metric\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Number of permutations\u001b[39;49;00m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# For reproducibility\u001b[39;49;00m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[0;32m     20\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Create a DataFrame for feature importance\u001b[39;00m\n\u001b[0;32m     23\u001b[0m feature_importances \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature\u001b[39m\u001b[38;5;124m\"\u001b[39m: x_data_f\u001b[38;5;241m.\u001b[39mcolumns,\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m\"\u001b[39m: results\u001b[38;5;241m.\u001b[39mimportances_mean\n\u001b[0;32m     26\u001b[0m })\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImportance\u001b[39m\u001b[38;5;124m\"\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\inspection\\_permutation_importance.py:289\u001b[0m, in \u001b[0;36mpermutation_importance\u001b[1;34m(estimator, X, y, scoring, n_repeats, n_jobs, random_state, sample_weight, max_samples)\u001b[0m\n\u001b[0;32m    285\u001b[0m     scorer \u001b[38;5;241m=\u001b[39m _MultimetricScorer(scorers\u001b[38;5;241m=\u001b[39mscorers_dict)\n\u001b[0;32m    287\u001b[0m baseline_score \u001b[38;5;241m=\u001b[39m _weights_scorer(scorer, estimator, X, y, sample_weight)\n\u001b[1;32m--> 289\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_calculate_permutation_scores\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(baseline_score, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    306\u001b[0m         name: _create_importances_bunch(\n\u001b[0;32m    307\u001b[0m             baseline_score[name],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m baseline_score\n\u001b[0;32m    312\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\joblib\\parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1692\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1693\u001b[0m \n\u001b[0;32m   1694\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1697\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1699\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1700\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1702\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\joblib\\parallel.py:1734\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1730\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1734\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\joblib\\parallel.py:736\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    730\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\paola\\anaconda3\\envs\\MLCourse\\lib\\site-packages\\joblib\\parallel.py:754\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 754\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m: A task has failed to un-serialize. Please ensure that the arguments of the function are all picklable."
     ]
    }
   ],
   "source": [
    "'''\n",
    "In a neural network, you don't directly get \"feature importances\" like in tree-based models (e.g., Random Forest or XGBoost). \n",
    "However, you can estimate feature importance by analyzing how sensitive the model's predictions are to changes in each feature. \n",
    "This method is often referred to as \"permutation importance\" or \"feature sensitivity analysis.\"\n",
    "\n",
    "Here's a Python script to compute and visualize the top 10 most important features based on permutation importance:\n",
    "'''\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Calculate permutation importance\n",
    "results = permutation_importance(\n",
    "    best_net,  # Trained model\n",
    "    x_data_f.values.astype(np.float32),  # Input data\n",
    "    y_data_f.astype(np.float32),  # Target values\n",
    "    scoring=\"neg_mean_squared_error\",  # Scoring metric\n",
    "    n_repeats=15,  # Number of permutations\n",
    "    random_state=42,  # For reproducibility\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Create a DataFrame for feature importance\n",
    "feature_importances = pd.DataFrame({\n",
    "    \"Feature\": x_data_f.columns,\n",
    "    \"Importance\": results.importances_mean\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Select the top 10 features\n",
    "top_10_features = feature_importances.head(10)\n",
    "\n",
    "# Plot the top 10 features\n",
    "plt.figure(figsize=(15, 9))\n",
    "plt.barh(top_10_features[\"Feature\"], top_10_features[\"Importance\"], align=\"center\")\n",
    "plt.gca().invert_yaxis()  # Highest importance on top\n",
    "plt.xlabel(\"Mean Importance\")\n",
    "plt.title(\"Top 10 Most Important Features\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Data\\\\Feature_Importance_Plot.png\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLCourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
