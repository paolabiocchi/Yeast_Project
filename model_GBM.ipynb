{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import uniform, randint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérification du dossier de résultats\n",
    "os.makedirs('results', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les fichiers\n",
    "X_file = \"data/X_matrix.csv\"\n",
    "Y_file = \"data/Y_matrix.csv\"\n",
    "\n",
    "print(\"Chargement des données...\")\n",
    "X = pd.read_csv(X_file)\n",
    "Y = pd.read_csv(Y_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S'assurer que Yeast_ID est une chaîne\n",
    "X['Yeast_ID'] = X['Yeast_ID'].astype(str)\n",
    "Y['Yeast_ID'] = Y['Yeast_ID'].astype(str)\n",
    "\n",
    "# S'assurer que les Yeast_ID sont alignés\n",
    "print(\"Vérification de l'ordre des Yeast_ID...\")\n",
    "if not all(X[\"Yeast_ID\"] == Y[\"Yeast_ID\"]):\n",
    "    raise ValueError(\"L'ordre des Yeast_ID ne correspond pas entre les deux fichiers.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer les données\n",
    "print(\"Préparation des données...\")\n",
    "X_data = X.drop(columns=[\"Yeast_ID\"]).fillna(0)  # Remplacer les valeurs manquantes par 0 dans X\n",
    "Y_data = Y.drop(columns=[\"Yeast_ID\"]).fillna(Y.drop(columns=[\"Yeast_ID\"]).mean())  # Remplacer les valeurs manquantes par la moyenne dans Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division des données en ensembles d'entraînement et de test\n",
    "print(\"Division des données en ensembles d'entraînement et de test...\")\n",
    "sss = ShuffleSplit(n_splits=1, test_size=0.25, random_state=42)\n",
    "train_index, test_index = next(sss.split(X_data, Y_data))\n",
    "\n",
    "X_train, X_test = X_data.iloc[train_index, :], X_data.iloc[test_index, :]\n",
    "y_train, y_test = Y_data.iloc[train_index, :], Y_data.iloc[test_index, :]\n",
    "\n",
    "# Mise à l'échelle des données\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "y_train_scaled = scaler.fit_transform(y_train)\n",
    "y_test_scaled = scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Définition des paramètres pour la recherche aléatoire...\")\n",
    "GBM_distributions = dict(\n",
    "    max_features=[\"auto\", \"log2\", \"sqrt\"],\n",
    "    learning_rate=uniform(1e-3, 1),\n",
    "    subsample=uniform(0, 1),\n",
    "    min_samples_split=randint(2, 100),\n",
    "    min_samples_leaf=randint(2, 100),\n",
    "    n_estimators=randint(10, 200),\n",
    "    criterion=['friedman_mse', 'squared_error'],\n",
    "    max_depth=randint(2, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement multitâche avec RandomizedSearchCV\n",
    "print(\"Lancement de l'entraînement multitâche avec Gradient Boosting...\")\n",
    "n_iterations = 100\n",
    "cross_val = 3\n",
    "num_jobs = -1\n",
    "\n",
    "multireg = MultiOutputRegressor(RandomizedSearchCV(\n",
    "    GradientBoostingRegressor(loss=\"squared_error\", n_iter_no_change=5),\n",
    "    GBM_distributions,\n",
    "    n_iter=n_iterations,\n",
    "    verbose=10,\n",
    "    cv=cross_val,\n",
    "    n_jobs=num_jobs\n",
    ")).fit(X_train_scaled, y_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions\n",
    "print(\"Prédictions sur les données de test...\")\n",
    "multi_reg_pred = multireg.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des résultats\n",
    "y_test_pred_df = pd.DataFrame(multi_reg_pred, index=y_test.index, columns=Y_data.columns)\n",
    "y_test_pred_df.to_csv('results/y_test_predicted_multitarget_GBM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance des caractéristiques\n",
    "print(\"Calcul des importances des caractéristiques...\")\n",
    "feature_importances = []\n",
    "for estimator in multireg.estimators_:\n",
    "    best_estimator = estimator.best_estimator_\n",
    "    importances = best_estimator.feature_importances_\n",
    "    feature_importances.append(importances)\n",
    "\n",
    "# Moyenne des importances\n",
    "average_feature_importances = pd.DataFrame(feature_importances).mean(axis=0)\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    \"Feature\": X_data.columns,\n",
    "    \"Importance\": average_feature_importances\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "feature_importances_df.to_csv('results/feature_importances_multitarget_GBM.csv')\n",
    "\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Enregistrement terminé. Les résultats sont sauvegardés dans le dossier 'results'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des métriques\n",
    "print(\"Calcul des métriques...\")\n",
    "mse = mean_squared_error(y_test_scaled, multi_reg_pred)\n",
    "r2 = r2_score(y_test_scaled, multi_reg_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.6f}\")\n",
    "print(f\"R² Score: {r2:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance des caractéristiques\n",
    "print(\"Calcul de l'importance des caractéristiques...\")\n",
    "top_mutations = feature_importances_df.head(10)\n",
    "print(\"\\nMutations ayant le plus d'impact sur le YPD doubling time :\")\n",
    "print(top_mutations)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_mutations[\"Feature\"], top_mutations[\"Importance\"], color=\"skyblue\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Mutation\")\n",
    "plt.title(\"Top 10 Mutations Impacting YPD Doubling Time\")\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Les résultats sont sauvegardés dans le dossier 'results/'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
