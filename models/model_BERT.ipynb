{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from preprocessing import *\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = \"data/X_matrix.csv\"\n",
    "Y = \"data/y_phenotype.csv\"\n",
    "\n",
    "print(\"Loading the data...\")\n",
    "\n",
    "# Load the column names (header)\n",
    "column_names = np.genfromtxt(X, delimiter=',', max_rows=1, dtype=str)[1:]  # Skip the first column if it's row names\n",
    "\n",
    "# Load the row names (index) from the first column and the data (excluding first column)\n",
    "data = np.loadtxt(X, delimiter=',', skiprows=1, usecols=range(1, 348523))\n",
    "row_names = np.loadtxt(X, delimiter=',', skiprows=1, usecols=0, dtype=str)\n",
    "\n",
    "# Create the DataFrame\n",
    "X_file = pd.DataFrame(data, index=row_names, columns=column_names)\n",
    "X_file = pd.DataFrame(data, columns=column_names)\n",
    "y_file = pd.read_csv(Y)\n",
    "\n",
    "X_data = X_file.drop(columns=[\"Yeast_ID\"])  # Remplacer les valeurs manquantes par 0 dans X\n",
    "y_data = y_file.drop(columns=[\"Yeast_ID\"])\n",
    "print(f\"Dimensions de X : {X_data.shape}\")\n",
    "print(f\"Dimensions de Y : {y_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data_f, y_data_f = preprocessed_data(X_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division des données en ensembles d'entraînement et de test\n",
    "print(\"Division des données en ensemble d'entraînement et de test...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data_f, y_data_f, test_size=0.2, random_state=42)\n",
    "\n",
    "# Affichage des dimensions des ensembles pour validation\n",
    "print(f\"Dimensions de X_train: {X_train.shape}\")\n",
    "print(f\"Dimensions de X_test: {X_test.shape}\")\n",
    "print(f\"Dimensions de y_train: {y_train.shape}\")\n",
    "print(f\"Dimensions de y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenize data\n",
    "def tokenize_data(texts):\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "train_encodings = tokenize_data(X_train.tolist())\n",
    "test_encodings = tokenize_data(X_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom Dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets\n",
    "train_dataset = CustomDataset(train_encodings, y_train.tolist())\n",
    "test_dataset = CustomDataset(test_encodings, y_test.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT model\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(set(y_data)))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # Output directory\n",
    "    num_train_epochs=3,              # Number of epochs\n",
    "    per_device_train_batch_size=8,   # Batch size for training\n",
    "    per_device_eval_batch_size=16,   # Batch size for evaluation\n",
    "    warmup_steps=500,                # Warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # Weight decay\n",
    "    logging_dir='./logs',            # Directory for logging\n",
    "    evaluation_strategy=\"epoch\",     # Evaluate at each epoch\n",
    "    save_strategy=\"epoch\",           # Save model at each epoch\n",
    "    load_best_model_at_end=True      # Load the best model at the end\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save_pretrained(\"bert_model\")\n",
    "tokenizer.save_pretrained(\"bert_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "predictions = trainer.predict(test_dataset)\n",
    "y_pred = torch.argmax(torch.tensor(predictions.predictions), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to CSV\n",
    "results_df = pd.DataFrame({\n",
    "    \"true_label\": y_test.tolist(),\n",
    "    \"predicted_label\": y_pred.tolist()\n",
    "})\n",
    "results_df.to_csv(\"results/y_test_predicted_BERT.csv\", index=False)\n",
    "\n",
    "print(\"Training complete, and predictions saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
